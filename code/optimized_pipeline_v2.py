#!/usr/bin/env python3
"""
–†–µ–≤–æ–ª—é—Ü–∏–æ–Ω–Ω—ã–π –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π pipeline v3.0 —Å Direct Join
–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: RAW ‚Üí cuDF ‚Üí Flame GPU ‚Üí ClickHouse Dictionary (Direct Join) ‚Üí Results

üöÄ –ö–õ–Æ–ß–ï–í–´–ï –£–õ–£–ß–®–ï–ù–ò–Ø v3.0:

1. **Direct Join —Å FLAT layout** - ~25x –±—ã—Å—Ç—Ä–µ–µ hash join
   - O(1) lookup –¥–ª—è –ø–∞—Ä—Ç–Ω–æ–º–µ—Ä–æ–≤ (–ø–ª–æ—Ç–Ω—ã–µ ID 1,2,3...)
   - O(1) lookup –¥–ª—è —Ç–∏–ø–æ–≤ –í–° (–±–∏—Ç–æ–≤—ã–µ –º–∞—Å–∫–∏)
   - –£—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –≥–ª–∞–≤–Ω–æ–≥–æ bottleneck –≤ –æ–±–æ–≥–∞—â–µ–Ω–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

2. **ClickHouse Dictionary —Å FLAT layout**
   - –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –¥–ª—è –ø–ª–æ—Ç–Ω—ã—Ö –∫–ª—é—á–µ–π
   - –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –¥–ª—è –Ω–∞—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö (4,722 –ø–∞—Ä—Ç–Ω–æ–º–µ—Ä–∞)
   - –°–≤–µ—Ä—Ö–±—ã—Å—Ç—Ä—ã–µ key-value –æ–ø–µ—Ä–∞—Ü–∏–∏ –≤ –ø–∞–º—è—Ç–∏

3. **–†–µ–≤–æ–ª—é—Ü–∏–æ–Ω–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –æ–±–æ–≥–∞—â–µ–Ω–∏—è**
   - –í–º–µ—Å—Ç–æ –º–µ–¥–ª–µ–Ω–Ω–æ–≥–æ pandas dict lookup
   - –ü—Ä—è–º–æ–µ –æ–±–æ–≥–∞—â–µ–Ω–∏–µ –≤ ClickHouse —á–µ—Ä–µ–∑ Direct Join
   - –í—Ä–µ–º—è –æ–±–æ–≥–∞—â–µ–Ω–∏—è: ~0.5-1 —Å–µ–∫ –≤–º–µ—Å—Ç–æ ~10-15 —Å–µ–∫

4. **–ü–æ–ª–Ω–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è Dictionary pipeline**
   - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –∏ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ Dictionary
   - –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –º–∞–ø–ø–∏–Ω–≥–æ–≤ pandas ‚Üî ClickHouse
   - Production-ready –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞

üìà –û–ñ–ò–î–ê–ï–ú–ê–Ø –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–¨:
- v2.0 (pandas dict): ~4-8 —Å–µ–∫
- v3.0 (Direct Join): ~2-3 —Å–µ–∫ (–±—ã—Å—Ç—Ä–µ–µ + –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ!)

üéØ –¶–ï–õ–¨: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—é –¥–æ 600M –∑–∞–ø–∏—Å–µ–π —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –≤—ã—Å–æ–∫–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
"""

import os
import sys
import pandas as pd
import numpy as np
import cudf
import pyarrow as pa
import clickhouse_connect
import logging
from datetime import datetime, date
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any
import time
from concurrent.futures import ThreadPoolExecutor
import yaml

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ —É—Ç–∏–ª–∏—Ç–∞–º
sys.path.append(str(Path(__file__).parent / 'utils'))
from config_loader import load_database_config

class OptimizedPipelineV3:
    """
    –§–∏–Ω–∞–ª—å–Ω—ã–π –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π pipeline v3.0 —Å Direct Join
    
    –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:
    1. RAW —Ç–∞–±–ª–∏—Ü–∞: –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ + —á–∏—Å–ª–æ–≤—ã–µ ID (–æ–±–æ–≥–∞—â–µ–Ω–Ω—ã–µ –≤ pandas)
    2. ClickHouse Dictionary (FLAT layout): —Å–≤–µ—Ä—Ö–±—ã—Å—Ç—Ä—ã–π lookup –¥–ª—è –æ–±–æ–≥–∞—â–µ–Ω–∏—è
    3. Results —Ç–∞–±–ª–∏—Ü–∞: —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã GPU + –¥–µ–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –ø–æ–ª—è (—á–µ—Ä–µ–∑ Direct Join)
    
    –ü–æ—Ç–æ–∫ –¥–∞–Ω–Ω—ã—Ö:
    Excel ‚Üí pandas (–æ–±–æ–≥–∞—â–µ–Ω–∏–µ) ‚Üí RAW table + Dictionary ‚Üí cuDF ‚Üí Flame GPU ‚Üí cuDF ‚Üí Direct Join ‚Üí Results table
    
    –ö–ª—é—á–µ–≤–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ v3.0:
    - Direct Join –≤–º–µ—Å—Ç–æ pandas dict lookup (~25x –±—ã—Å—Ç—Ä–µ–µ hash join)
    - FLAT layout Dictionary –¥–ª—è O(1) lookup
    - –£—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –≥–ª–∞–≤–Ω–æ–≥–æ bottleneck –≤ –æ–±–æ–≥–∞—â–µ–Ω–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    """
    
    def __init__(self):
        self.logger = self._setup_logging()
        self.config = load_database_config()
        self.client = None
        
        # –ú–∞–ø–ø–∏–Ω–≥–∏ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –æ–±–æ–≥–∞—â–µ–Ω–∏—è –≤ pandas
        self.partno_mapping = {}
        self.ac_type_mapping = {}
        self.component_type_mapping = {}
        self.owner_mapping = {}
        self.condition_mapping = {}
        
        # –û–±—Ä–∞—Ç–Ω—ã–µ –º–∞–ø–ø–∏–Ω–≥–∏ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è Dictionary
        self.reverse_partno_mapping = {}
        self.reverse_ac_type_mapping = {}
        self.reverse_component_type_mapping = {}
        self.reverse_owner_mapping = {}
        self.reverse_condition_mapping = {}
        
    def _setup_logging(self) -> logging.Logger:
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
        os.makedirs('test_output', exist_ok=True)
        
        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
        
        logger = logging.getLogger('optimized_pipeline_v3')
        logger.setLevel(logging.INFO)
        
        # –£–±–∏—Ä–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏
        for handler in logger.handlers[:]:
            logger.removeHandler(handler)
        
        # –§–∞–π–ª–æ–≤—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫
        file_handler = logging.FileHandler('test_output/optimized_pipeline_v3.log', mode='w')
        file_handler.setLevel(logging.DEBUG)
        file_handler.setFormatter(formatter)
        
        # –ö–æ–Ω—Å–æ–ª—å–Ω—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)
        console_handler.setFormatter(formatter)
        
        logger.addHandler(file_handler)
        logger.addHandler(console_handler)
        
        return logger
    
    def connect_clickhouse(self) -> bool:
        """–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ ClickHouse"""
        try:
            self.client = clickhouse_connect.get_client(
                host=self.config['host'],
                port=self.config['port'],
                database=self.config['database'],
                username=self.config.get('user'),
                password=self.config.get('password'),
                settings={'max_threads': 8}
            )
            
            # –¢–µ—Å—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
            self.client.query("SELECT 1")
            self.logger.info(f"‚úÖ ClickHouse –ø–æ–¥–∫–ª—é—á–µ–Ω: {self.config['host']}:{self.config['port']}")
            return True
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ ClickHouse: {e}")
            return False

    def create_dictionary_tables(self) -> bool:
        """–°–æ–∑–¥–∞–Ω–∏–µ –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã—Ö —Ç–∞–±–ª–∏—Ü –¥–ª—è ClickHouse Dictionary —Å FLAT layout"""
        self.logger.info("üèóÔ∏è –°–æ–∑–¥–∞–Ω–∏–µ Dictionary —Ç–∞–±–ª–∏—Ü –¥–ª—è Direct Join...")
        
        # 1. –¢–∞–±–ª–∏—Ü–∞ –ø–∞—Ä—Ç–Ω–æ–º–µ—Ä–æ–≤ (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ –¥–ª—è FLAT layout)
        partno_dict_sql = """
        CREATE TABLE IF NOT EXISTS dict_partno_flat (
            partno_id UInt16,          -- FLAT layout key (–ø–ª–æ—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è 1,2,3...)
            partno String,
            component_name String,
            component_type String
        ) ENGINE = Memory
        """
        
        # 2. –¢–∞–±–ª–∏—Ü–∞ —Ç–∏–ø–æ–≤ –í–° (–±–∏—Ç–æ–≤—ã–µ –º–∞—Å–∫–∏)
        ac_type_dict_sql = """
        CREATE TABLE IF NOT EXISTS dict_ac_type_flat (
            ac_type_mask UInt8,        -- FLAT layout key (32, 64, 96, 128)
            ac_typ String,
            description String,
            helicopter_class String
        ) ENGINE = Memory
        """
        
        # 3. –¢–∞–±–ª–∏—Ü–∞ –≤–ª–∞–¥–µ–ª—å—Ü–µ–≤
        owner_dict_sql = """
        CREATE TABLE IF NOT EXISTS dict_owner_flat (
            owner_id UInt8,            -- FLAT layout key (1,2,3...)
            owner String,
            owner_type String,
            lease_restrictions String
        ) ENGINE = Memory
        """
        
        # 4. –¢–∞–±–ª–∏—Ü–∞ —Å–æ—Å—Ç–æ—è–Ω–∏–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        condition_dict_sql = """
        CREATE TABLE IF NOT EXISTS dict_condition_flat (
            condition_mask UInt8,      -- FLAT layout key (–±–∏—Ç–æ–≤—ã–µ –º–∞—Å–∫–∏)
            condition String,
            description String,
            maintenance_required UInt8
        ) ENGINE = Memory
        """
        
        try:
            self.client.command(partno_dict_sql)
            self.client.command(ac_type_dict_sql)
            self.client.command(owner_dict_sql)
            self.client.command(condition_dict_sql)
            
            self.logger.info("‚úÖ Dictionary —Ç–∞–±–ª–∏—Ü—ã —Å–æ–∑–¥–∞–Ω—ã –¥–ª—è FLAT layout")
            return True
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è Dictionary —Ç–∞–±–ª–∏—Ü: {e}")
            return False

    def create_clickhouse_dictionaries(self) -> bool:
        """–°–æ–∑–¥–∞–Ω–∏–µ ClickHouse Dictionary –æ–±—ä–µ–∫—Ç–æ–≤ —Å FLAT layout –¥–ª—è Direct Join"""
        self.logger.info("üìö –°–æ–∑–¥–∞–Ω–∏–µ ClickHouse Dictionary —Å FLAT layout...")
        
        # 1. Dictionary –¥–ª—è –ø–∞—Ä—Ç–Ω–æ–º–µ—Ä–æ–≤ (FLAT layout –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Å–∫–æ—Ä–æ—Å—Ç–∏)
        partno_dict_ddl = f"""
        CREATE OR REPLACE DICTIONARY partno_dict_flat (
            partno_id UInt16,
            partno String,
            component_name String,
            component_type String
        )
        PRIMARY KEY partno_id
        SOURCE(CLICKHOUSE(
            HOST '{self.config['host']}'
            PORT {self.config['port']}
            TABLE 'dict_partno_flat'
            DB '{self.config['database']}'
        ))
        LAYOUT(FLAT(INITIAL_ARRAY_SIZE 5000 MAX_ARRAY_SIZE 5000))
        LIFETIME(MIN 0 MAX 3600)
        """
        
        # 2. Dictionary –¥–ª—è —Ç–∏–ø–æ–≤ –í–° (FLAT layout –¥–ª—è –±–∏—Ç–æ–≤—ã—Ö –º–∞—Å–æ–∫)
        ac_type_dict_ddl = f"""
        CREATE OR REPLACE DICTIONARY ac_type_dict_flat (
            ac_type_mask UInt8,
            ac_typ String,
            description String,
            helicopter_class String
        )
        PRIMARY KEY ac_type_mask
        SOURCE(CLICKHOUSE(
            HOST '{self.config['host']}'
            PORT {self.config['port']}
            TABLE 'dict_ac_type_flat'
            DB '{self.config['database']}'
        ))
        LAYOUT(FLAT(INITIAL_ARRAY_SIZE 256 MAX_ARRAY_SIZE 256))
        LIFETIME(MIN 0 MAX 3600)
        """
        
        # 3. Dictionary –¥–ª—è –≤–ª–∞–¥–µ–ª—å—Ü–µ–≤ (FLAT layout)
        owner_dict_ddl = f"""
        CREATE OR REPLACE DICTIONARY owner_dict_flat (
            owner_id UInt8,
            owner String,
            owner_type String,
            lease_restrictions String
        )
        PRIMARY KEY owner_id
        SOURCE(CLICKHOUSE(
            HOST '{self.config['host']}'
            PORT {self.config['port']}
            TABLE 'dict_owner_flat'
            DB '{self.config['database']}'
        ))
        LAYOUT(FLAT(INITIAL_ARRAY_SIZE 256 MAX_ARRAY_SIZE 256))
        LIFETIME(MIN 0 MAX 3600)
        """
        
        # 4. Dictionary –¥–ª—è —Å–æ—Å—Ç–æ—è–Ω–∏–π (FLAT layout)
        condition_dict_ddl = f"""
        CREATE OR REPLACE DICTIONARY condition_dict_flat (
            condition_mask UInt8,
            condition String,
            description String,
            maintenance_required UInt8
        )
        PRIMARY KEY condition_mask
        SOURCE(CLICKHOUSE(
            HOST '{self.config['host']}'
            PORT {self.config['port']}
            TABLE 'dict_condition_flat'
            DB '{self.config['database']}'
        ))
        LAYOUT(FLAT(INITIAL_ARRAY_SIZE 256 MAX_ARRAY_SIZE 256))
        LIFETIME(MIN 0 MAX 3600)
        """
        
        try:
            self.client.command(partno_dict_ddl)
            self.client.command(ac_type_dict_ddl)
            self.client.command(owner_dict_ddl)
            self.client.command(condition_dict_ddl)
            
            self.logger.info("‚úÖ ClickHouse Dictionary —Å FLAT layout —Å–æ–∑–¥–∞–Ω—ã")
            return True
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è ClickHouse Dictionary: {e}")
            return False
    
    def create_raw_table(self) -> bool:
        """–°–æ–∑–¥–∞–Ω–∏–µ RAW —Ç–∞–±–ª–∏—Ü—ã"""
        raw_table_sql = """
        CREATE TABLE IF NOT EXISTS helicopter_components_raw (
            -- –û—Å–Ω–æ–≤–Ω—ã–µ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã (–∏—Å—Ö–æ–¥–Ω—ã–µ)
            partno String,
            serialno String,  -- –∫–ª—é—á —Å–≤—è–∑–∏
            ac_typ String,
            component_type String,
            location String,
            owner String,
            condition String,
            
            -- –ß–∏—Å–ª–æ–≤—ã–µ ID –¥–ª—è GPU (–æ–±–æ–≥–∞—â–µ–Ω–Ω—ã–µ –≤ pandas)
            partno_id UInt16,
            ac_type_mask UInt8,     -- –±–∏—Ç–æ–≤—ã–µ –º–∞—Å–∫–∏: –ú–∏-26=128, –ú–∏-17=64, –ú–∏-8–¢=32
            component_type_id UInt8,
            owner_id UInt8,
            condition_mask UInt8,
            
            -- –†–µ—Å—É—Ä—Å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            ll Float32,
            oh Float32,
            oh_threshold Float32,
            sne Float32,
            ppr Float32,
            
            -- –î–∞—Ç—ã
            mfg_date Nullable(Date),
            removal_date Nullable(Date),
            target_date Nullable(Date),
            
            -- –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            version_date Date DEFAULT today(),
            load_timestamp DateTime DEFAULT now()
            
        ) ENGINE = MergeTree()
        PARTITION BY (component_type, toYYYYMM(version_date))
        ORDER BY (serialno, component_type_id, partno_id, version_date)
        SETTINGS index_granularity = 8192
        """
        
        try:
            self.client.command(raw_table_sql)
            self.logger.info("‚úÖ RAW —Ç–∞–±–ª–∏—Ü–∞ —Å–æ–∑–¥–∞–Ω–∞/–ø—Ä–æ–≤–µ—Ä–µ–Ω–∞")
            return True
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è RAW —Ç–∞–±–ª–∏—Ü—ã: {e}")
            return False
    
    def create_results_table(self) -> bool:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        results_table_sql = """
        CREATE TABLE IF NOT EXISTS helicopter_simulation_results (
            -- –ö–ª—é—á —Å–≤—è–∑–∏
            serialno String,
            
            -- –†–µ–∑—É–ª—å—Ç–∞—Ç—ã GPU —Å–∏–º—É–ª—è—Ü–∏–∏
            predicted_failure_days UInt16,
            maintenance_priority UInt8,
            replacement_recommended UInt8,  -- 0/1
            remaining_resource_pct Float32,
            risk_score Float32,
            
            -- –î–µ–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –ø–æ–ª—è –∏–∑ RAW (–¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –±–µ–∑ JOIN)
            partno String,
            component_name String,
            component_type String,
            ac_typ String,
            location String,
            owner String,
            condition String,
            
            -- –ò—Å—Ö–æ–¥–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã (–¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞)
            current_ll Float32,
            current_oh Float32,
            oh_threshold Float32,
            
            -- –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å–∏–º—É–ª—è—Ü–∏–∏
            simulation_id String,
            simulation_date DateTime DEFAULT now(),
            model_version String,
            input_version_date Date,
            processing_time_ms UInt32
            
        ) ENGINE = MergeTree()
        PARTITION BY (component_type, toYYYYMM(simulation_date))
        ORDER BY (serialno, simulation_id)
        SETTINGS index_granularity = 8192
        """
        
        try:
            self.client.command(results_table_sql)
            self.logger.info("‚úÖ Results —Ç–∞–±–ª–∏—Ü–∞ —Å–æ–∑–¥–∞–Ω–∞/–ø—Ä–æ–≤–µ—Ä–µ–Ω–∞")
            return True
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è Results —Ç–∞–±–ª–∏—Ü—ã: {e}")
            return False
    
    def load_excel_data(self, excel_path: str) -> pd.DataFrame:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Excel"""
        self.logger.info(f"üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ {excel_path}")
        
        try:
            # –ó–∞–≥—Ä—É–∑–∫–∞ –æ—Å–Ω–æ–≤–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            df = pd.read_excel(excel_path, sheet_name='Status_Components')
            
            # –ó–∞–≥—Ä—É–∑–∫–∞ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–æ–≤
            md_dict = pd.read_excel('data_input/master_data/MD_Dictionary.xlsx')
            md_comp = pd.read_excel('data_input/master_data/MD_–°omponents.xlsx')
            
            self.logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –∑–∞–ø–∏—Å–µ–π –∏–∑ Excel")
            return df, md_dict, md_comp
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ Excel: {e}")
            raise
    
    def create_mappings_and_populate_dictionaries(self, df: pd.DataFrame, md_dict: pd.DataFrame, md_comp: pd.DataFrame) -> None:
        """–°–æ–∑–¥–∞–Ω–∏–µ –º–∞–ø–ø–∏–Ω–≥–æ–≤ –¥–ª—è –æ–±–æ–≥–∞—â–µ–Ω–∏—è –∏ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ ClickHouse Dictionary"""
        self.logger.info("üî¢ –°–æ–∑–¥–∞–Ω–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö –º–∞–ø–ø–∏–Ω–≥–æ–≤ –∏ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ Dictionary...")
        
        start_time = time.time()
        
        # –ü–∞—Ä—Ç–Ω–æ–º–µ—Ä—ã (–ø–ª–æ—Ç–Ω—ã–µ ID –¥–ª—è FLAT layout)
        unique_partnos = df['partno'].dropna().unique()
        self.partno_mapping = {partno: idx + 1 for idx, partno in enumerate(unique_partnos)}
        self.reverse_partno_mapping = {idx + 1: partno for idx, partno in enumerate(unique_partnos)}
        
        # –¢–∏–ø—ã –í–° (–±–∏—Ç–æ–≤—ã–µ –º–∞—Å–∫–∏ –¥–ª—è FLAT layout)
        self.ac_type_mapping = {
            '–ú–∏-26': 128,
            '–ú–∏-17': 64, 
            '–ú–∏-8–¢': 32,
            '–ö–∞-32': 16,
            'AS-350': 8,
            'AS-355': 4,
            'R-44': 2
        }
        self.reverse_ac_type_mapping = {v: k for k, v in self.ac_type_mapping.items()}
        
        # –¢–∏–ø—ã –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        unique_components = df['component_type'].dropna().unique()
        self.component_type_mapping = {comp: idx + 1 for idx, comp in enumerate(unique_components)}
        self.reverse_component_type_mapping = {idx + 1: comp for idx, comp in enumerate(unique_components)}
        
        # –í–ª–∞–¥–µ–ª—å—Ü—ã
        unique_owners = df['owner'].dropna().unique()
        self.owner_mapping = {owner: idx + 1 for idx, owner in enumerate(unique_owners)}
        self.reverse_owner_mapping = {idx + 1: owner for idx, owner in enumerate(unique_owners)}
        
        # –°–æ—Å—Ç–æ—è–Ω–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ (–±–∏—Ç–æ–≤—ã–µ –º–∞—Å–∫–∏)
        self.condition_mapping = {
            '–ò—Å–ø—Ä–∞–≤–µ–Ω': 1,
            '–ù–µ–∏—Å–ø—Ä–∞–≤–µ–Ω': 2,
            '–¢—Ä–µ–±—É–µ—Ç —Ä–µ–º–æ–Ω—Ç–∞': 4,
            '–í —Ä–µ–º–æ–Ω—Ç–µ': 8,
            '–°–ø–∏—Å–∞–Ω': 16
        }
        self.reverse_condition_mapping = {v: k for k, v in self.condition_mapping.items()}
        
        # –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ Dictionary —Ç–∞–±–ª–∏—Ü –¥–ª—è Direct Join
        self._populate_partno_dictionary(df, md_comp)
        self._populate_ac_type_dictionary()
        self._populate_owner_dictionary(unique_owners)
        self._populate_condition_dictionary()
        
        duration = time.time() - start_time
        self.logger.info(f"‚úÖ –ú–∞–ø–ø–∏–Ω–≥–∏ —Å–æ–∑–¥–∞–Ω—ã –∏ Dictionary –∑–∞–ø–æ–ª–Ω–µ–Ω—ã –∑–∞ {duration:.2f} —Å–µ–∫")
        self.logger.info(f"üìä –°–æ–∑–¥–∞–Ω–æ: {len(unique_partnos)} –ø–∞—Ä—Ç–Ω–æ–º–µ—Ä–æ–≤, {len(unique_components)} —Ç–∏–ø–æ–≤, {len(unique_owners)} –≤–ª–∞–¥–µ–ª—å—Ü–µ–≤")

    def _populate_partno_dictionary(self, df: pd.DataFrame, md_comp: pd.DataFrame) -> None:
        """–ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ Dictionary –ø–∞—Ä—Ç–Ω–æ–º–µ—Ä–æ–≤ –¥–ª—è FLAT layout"""
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –ø–∞—Ä—Ç–Ω–æ–º–µ—Ä–æ–≤ —Å –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏
        partno_data = []
        for partno_id, partno in self.reverse_partno_mapping.items():
            # –ù–∞—Ö–æ–¥–∏–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ –≤ –æ—Å–Ω–æ–≤–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            component_rows = df[df['partno'] == partno]
            if not component_rows.empty:
                component_type = component_rows['component_type'].iloc[0]
                
                # –ò—â–µ–º –ø–æ–¥—Ä–æ–±–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –≤ MD_Components
                component_name = partno  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
                if md_comp is not None and not md_comp.empty:
                    comp_match = md_comp[md_comp['partno'] == partno]
                    if not comp_match.empty and 'component_name' in comp_match.columns:
                        component_name = comp_match['component_name'].iloc[0]
                
                partno_data.append([partno_id, partno, component_name, component_type])
        
        if partno_data:
            self.client.insert('dict_partno_flat', partno_data,
                             column_names=['partno_id', 'partno', 'component_name', 'component_type'])
            self.logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(partno_data)} –ø–∞—Ä—Ç–Ω–æ–º–µ—Ä–æ–≤ –≤ Dictionary")

    def _populate_ac_type_dictionary(self) -> None:
        """–ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ Dictionary —Ç–∏–ø–æ–≤ –í–° –¥–ª—è FLAT layout"""
        
        ac_type_data = []
        ac_type_descriptions = {
            '–ú–∏-26': '–¢—è–∂–µ–ª—ã–π –º–Ω–æ–≥–æ—Ü–µ–ª–µ–≤–æ–π –≤–µ—Ä—Ç–æ–ª–µ—Ç',
            '–ú–∏-17': '–°—Ä–µ–¥–Ω–∏–π –º–Ω–æ–≥–æ—Ü–µ–ª–µ–≤–æ–π –≤–µ—Ä—Ç–æ–ª–µ—Ç', 
            '–ú–∏-8–¢': '–°—Ä–µ–¥–Ω–∏–π —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω—ã–π –≤–µ—Ä—Ç–æ–ª–µ—Ç',
            '–ö–∞-32': '–ö–æ—Ä–∞–±–µ–ª—å–Ω—ã–π –ø–æ–∏—Å–∫–æ–≤–æ-—Å–ø–∞—Å–∞—Ç–µ–ª—å–Ω—ã–π',
            'AS-350': '–õ–µ–≥–∫–∏–π –º–Ω–æ–≥–æ—Ü–µ–ª–µ–≤–æ–π',
            'AS-355': '–õ–µ–≥–∫–∏–π –¥–≤—É—Ö–¥–≤–∏–≥–∞—Ç–µ–ª—å–Ω—ã–π',
            'R-44': '–°–≤–µ—Ä—Ö–ª–µ–≥–∫–∏–π —É—á–µ–±–Ω–æ-—Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–π'
        }
        
        helicopter_classes = {
            '–ú–∏-26': '–¢—è–∂–µ–ª—ã–π',
            '–ú–∏-17': '–°—Ä–µ–¥–Ω–∏–π', 
            '–ú–∏-8–¢': '–°—Ä–µ–¥–Ω–∏–π',
            '–ö–∞-32': '–°—Ä–µ–¥–Ω–∏–π',
            'AS-350': '–õ–µ–≥–∫–∏–π',
            'AS-355': '–õ–µ–≥–∫–∏–π',
            'R-44': '–°–≤–µ—Ä—Ö–ª–µ–≥–∫–∏–π'
        }
        
        for ac_type_mask, ac_typ in self.reverse_ac_type_mapping.items():
            description = ac_type_descriptions.get(ac_typ, '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø')
            helicopter_class = helicopter_classes.get(ac_typ, '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π')
            ac_type_data.append([ac_type_mask, ac_typ, description, helicopter_class])
        
        if ac_type_data:
            self.client.insert('dict_ac_type_flat', ac_type_data,
                             column_names=['ac_type_mask', 'ac_typ', 'description', 'helicopter_class'])
            self.logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(ac_type_data)} —Ç–∏–ø–æ–≤ –í–° –≤ Dictionary")

    def _populate_owner_dictionary(self, unique_owners: list) -> None:
        """–ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ Dictionary –≤–ª–∞–¥–µ–ª—å—Ü–µ–≤ –¥–ª—è FLAT layout"""
        
        owner_data = []
        owner_types = {
            'GTLK': '–õ–∏–∑–∏–Ω–≥–æ–≤–∞—è –∫–æ–º–ø–∞–Ω–∏—è',
            'SBER': '–ë–∞–Ω–∫/–õ–∏–∑–∏–Ω–≥',
            '–ß–∞—Å—Ç–Ω–∞—è': '–ß–∞—Å—Ç–Ω—ã–π –≤–ª–∞–¥–µ–ª–µ—Ü',
            '–ì–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω–∞—è': '–ì–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω–∞—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è'
        }
        
        lease_restrictions = {
            'GTLK': '–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –ø–æ –ª–∏–∑–∏–Ω–≥—É',
            'SBER': '–ë–∞–Ω–∫–æ–≤—Å–∫–∏–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è',
            '–ß–∞—Å—Ç–Ω–∞—è': '–ù–µ—Ç –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π',
            '–ì–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω–∞—è': '–ì–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è'
        }
        
        for owner_id, owner in self.reverse_owner_mapping.items():
            owner_type = '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π'
            restrictions = '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'
            
            for key in owner_types:
                if key in owner:
                    owner_type = owner_types[key]
                    restrictions = lease_restrictions[key]
                    break
            
            owner_data.append([owner_id, owner, owner_type, restrictions])
        
        if owner_data:
            self.client.insert('dict_owner_flat', owner_data,
                             column_names=['owner_id', 'owner', 'owner_type', 'lease_restrictions'])
            self.logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(owner_data)} –≤–ª–∞–¥–µ–ª—å—Ü–µ–≤ –≤ Dictionary")

    def _populate_condition_dictionary(self) -> None:
        """–ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ Dictionary —Å–æ—Å—Ç–æ—è–Ω–∏–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –¥–ª—è FLAT layout"""
        
        condition_data = []
        condition_descriptions = {
            '–ò—Å–ø—Ä–∞–≤–µ–Ω': '–ö–æ–º–ø–æ–Ω–µ–Ω—Ç –≤ —Ä–∞–±–æ—á–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏',
            '–ù–µ–∏—Å–ø—Ä–∞–≤–µ–Ω': '–ö–æ–º–ø–æ–Ω–µ–Ω—Ç –Ω–µ–∏—Å–ø—Ä–∞–≤–µ–Ω, —Ç—Ä–µ–±—É–µ—Ç –∑–∞–º–µ–Ω—ã',
            '–¢—Ä–µ–±—É–µ—Ç —Ä–µ–º–æ–Ω—Ç–∞': '–ö–æ–º–ø–æ–Ω–µ–Ω—Ç —Ç—Ä–µ–±—É–µ—Ç –ø–ª–∞–Ω–æ–≤–æ–≥–æ —Ä–µ–º–æ–Ω—Ç–∞',
            '–í —Ä–µ–º–æ–Ω—Ç–µ': '–ö–æ–º–ø–æ–Ω–µ–Ω—Ç –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —Ä–µ–º–æ–Ω—Ç–µ',
            '–°–ø–∏—Å–∞–Ω': '–ö–æ–º–ø–æ–Ω–µ–Ω—Ç —Å–ø–∏—Å–∞–Ω, –Ω–µ –ø–æ–¥–ª–µ–∂–∏—Ç –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—é'
        }
        
        maintenance_required = {
            '–ò—Å–ø—Ä–∞–≤–µ–Ω': 0,
            '–ù–µ–∏—Å–ø—Ä–∞–≤–µ–Ω': 1,
            '–¢—Ä–µ–±—É–µ—Ç —Ä–µ–º–æ–Ω—Ç–∞': 1,
            '–í —Ä–µ–º–æ–Ω—Ç–µ': 1,
            '–°–ø–∏—Å–∞–Ω': 0
        }
        
        for condition_mask, condition in self.reverse_condition_mapping.items():
            description = condition_descriptions.get(condition, '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ')
            maintenance = maintenance_required.get(condition, 1)
            condition_data.append([condition_mask, condition, description, maintenance])
        
        if condition_data:
            self.client.insert('dict_condition_flat', condition_data,
                             column_names=['condition_mask', 'condition', 'description', 'maintenance_required'])
            self.logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(condition_data)} —Å–æ—Å—Ç–æ—è–Ω–∏–π –≤ Dictionary")
        
        # –í–ª–∞–¥–µ–ª—å—Ü—ã
        self.owner_mapping = {
            '–Æ–¢-–í–£': 1, 'UTE': 2, '–ì–¢–õ–ö': 3, '–°–ë–ï–† –õ–ò–ó–ò–ù–ì': 4,
            '–ì–ü–ú': 5, '–ê–û –ì–ü–ú': 6, '–ò–ü': 7, '–ê–†–í': 8, '–ò': 9
        }
        
        # –°–æ—Å—Ç–æ—è–Ω–∏—è (–±–∏—Ç–æ–≤—ã–µ –º–∞—Å–∫–∏)
        self.condition_mapping = {
            '–ò–°–ü–†–ê–í–ù–´–ô': 7,
            '–ù–ï–ò–°–ü–†–ê–í–ù–´–ô': 4,
            '–î–û–ù–û–†': 1,
            '–°–ù–Ø–¢': 0,
            '–ù–ï –£–°–¢–ê–ù–û–í–õ–ï–ù': 6,
            '–ü–û–°–¢–ê–í–ö–ê': 3
        }
        
        self.logger.info(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ –º–∞–ø–ø–∏–Ω–≥–æ–≤: {len(self.partno_mapping)} –ø–∞—Ä—Ç–Ω–æ–º–µ—Ä–æ–≤, "
                        f"{len(self.component_type_mapping)} –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤")
    
    def enrich_dataframe(self, df: pd.DataFrame) -> pd.DataFrame:
        """–û–±–æ–≥–∞—â–µ–Ω–∏–µ DataFrame —á–∏—Å–ª–æ–≤—ã–º–∏ –ø–æ–ª—è–º–∏"""
        self.logger.info("üíé –û–±–æ–≥–∞—â–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —á–∏—Å–ª–æ–≤—ã–º–∏ –ø–æ–ª—è–º–∏...")
        
        start_time = time.time()
        
        # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –¥–ª—è –æ–±–æ–≥–∞—â–µ–Ω–∏—è
        enriched_df = df.copy()
        
        # –î–æ–±–∞–≤–ª—è–µ–º —á–∏—Å–ª–æ–≤—ã–µ ID
        enriched_df['partno_id'] = enriched_df['partno'].map(self.partno_mapping).fillna(0).astype('uint16')
        enriched_df['ac_type_mask'] = enriched_df['ac_typ'].map(self.ac_type_mapping).fillna(0).astype('uint8')
        enriched_df['component_type_id'] = enriched_df['component_type'].map(self.component_type_mapping).fillna(0).astype('uint8')
        enriched_df['owner_id'] = enriched_df['owner'].map(self.owner_mapping).fillna(0).astype('uint8')
        enriched_df['condition_mask'] = enriched_df['condition'].map(self.condition_mapping).fillna(0).astype('uint8')
        
        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        enriched_df['version_date'] = pd.Timestamp.today().date()
        enriched_df['load_timestamp'] = pd.Timestamp.now()
        
        duration = time.time() - start_time
        self.logger.info(f"‚úÖ –û–±–æ–≥–∞—â–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞ {duration:.2f} —Å–µ–∫")
        
        return enriched_df
    
    def parallel_raw_loading(self, enriched_df: pd.DataFrame) -> None:
        """–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –≤ RAW —Ç–∞–±–ª–∏—Ü—É"""
        def load_to_raw():
            try:
                start_time = time.time()
                
                # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è ClickHouse
                columns_to_load = [
                    'partno', 'serialno', 'ac_typ', 'component_type', 'location', 'owner', 'condition',
                    'partno_id', 'ac_type_mask', 'component_type_id', 'owner_id', 'condition_mask',
                    'll', 'oh', 'oh_threshold', 'sne', 'ppr',
                    'mfg_date', 'removal_date', 'target_date', 'version_date', 'load_timestamp'
                ]
                
                raw_data = enriched_df[columns_to_load].copy()
                
                # –ó–∞–≥—Ä—É–∑–∫–∞ —á–µ—Ä–µ–∑ Arrow
                table = pa.Table.from_pandas(raw_data)
                
                self.client.insert_arrow(
                    'helicopter_components_raw',
                    table,
                    settings={'async_insert': 1}
                )
                
                duration = time.time() - start_time
                self.logger.info(f"‚úÖ RAW –¥–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∑–∞ {duration:.2f} —Å–µ–∫")
                
            except Exception as e:
                self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ RAW –¥–∞–Ω–Ω—ã—Ö: {e}")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
        with ThreadPoolExecutor(max_workers=1) as executor:
            future = executor.submit(load_to_raw)
            return future
    
    def prepare_gpu_data(self, enriched_df: pd.DataFrame) -> cudf.DataFrame:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è GPU"""
        self.logger.info("üöÄ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è GPU...")
        
        start_time = time.time()
        
        # –í—ã–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–æ–≤—ã–µ –ø–æ–ª—è –¥–ª—è GPU
        gpu_columns = [
            'serialno', 'partno_id', 'ac_type_mask', 'component_type_id', 
            'owner_id', 'condition_mask', 'll', 'oh', 'oh_threshold', 'sne', 'ppr'
        ]
        
        gpu_data = enriched_df[gpu_columns].copy()
        
        # –ü—Ä—è–º–æ–π transfer pandas ‚Üí cuDF (–±—ã—Å—Ç—Ä–µ–µ –¥–ª—è –Ω–µ–±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö)
        cudf_data = cudf.from_pandas(gpu_data)
        
        duration = time.time() - start_time
        self.logger.info(f"‚úÖ GPU –¥–∞–Ω–Ω—ã–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã –∑–∞ {duration:.2f} —Å–µ–∫")
        self.logger.info(f"üìä GPU DataFrame: {len(cudf_data)} –∑–∞–ø–∏—Å–µ–π, {cudf_data.memory_usage(deep=True).sum() / 1024**2:.1f} MB")
        
        return cudf_data
    
    def simulate_flame_gpu(self, cudf_data: cudf.DataFrame) -> cudf.DataFrame:
        """–°–∏–º—É–ª—è—Ü–∏—è Flame GPU (–∑–∞–≥–ª—É—à–∫–∞ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏)"""
        self.logger.info("üî• –ó–∞–ø—É—Å–∫ Flame GPU —Å–∏–º—É–ª—è—Ü–∏–∏...")
        
        start_time = time.time()
        
        # –ò–º–∏—Ç–∞—Ü–∏—è GPU —Ä–∞—Å—á–µ—Ç–æ–≤
        # –í —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –∑–¥–µ—Å—å –±—É–¥–µ—Ç –≤—ã–∑–æ–≤ Flame GPU –∞–≥–µ–Ω—Ç–æ–≤
        
        # –°–æ–∑–¥–∞–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
        n_records = len(cudf_data)
        
        results = cudf.DataFrame({
            'serialno': cudf_data['serialno'].copy(),
            'predicted_failure_days': cudf.Series(np.random.randint(30, 1000, n_records), dtype='uint16'),
            'maintenance_priority': cudf.Series(np.random.randint(1, 6, n_records), dtype='uint8'),
            'replacement_recommended': cudf.Series(np.random.randint(0, 2, n_records), dtype='uint8'),
            'remaining_resource_pct': cudf.Series(np.random.uniform(0, 100, n_records), dtype='float32'),
            'risk_score': cudf.Series(np.random.uniform(0, 1, n_records), dtype='float32')
        })
        
        # –ò–º–∏—Ç–∞—Ü–∏—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏ –ø–æ—Å–ª–µ 600M —Ä–∞—Å—á–µ—Ç–æ–≤
        results = results.drop_duplicates(subset=['serialno'])
        
        duration = time.time() - start_time
        self.logger.info(f"‚úÖ Flame GPU —Å–∏–º—É–ª—è—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {duration:.2f} —Å–µ–∫")
        self.logger.info(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {len(results)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π")
        
        return results
    
    def enrich_results_with_direct_join(self, gpu_results: cudf.DataFrame, simulation_id: str) -> bool:
        """–û–±–æ–≥–∞—â–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —á–µ—Ä–µ–∑ ClickHouse Direct Join (~25x –±—ã—Å—Ç—Ä–µ–µ)"""
        self.logger.info("üöÄ –û–±–æ–≥–∞—â–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —á–µ—Ä–µ–∑ Direct Join...")
        
        start_time = time.time()
        
        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º cuDF ‚Üí pandas –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏
            results_df = gpu_results.to_pandas()
            
            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é —Ç–∞–±–ª–∏—Ü—É –¥–ª—è GPU —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            temp_table_sql = """
            CREATE TEMPORARY TABLE temp_gpu_results (
                serialno String,
                predicted_failure_days UInt16,
                maintenance_priority UInt8,
                replacement_recommended UInt8,
                remaining_resource_pct Float32,
                risk_score Float32
            )
            """
            
            self.client.command(temp_table_sql)
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º GPU —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—É—é —Ç–∞–±–ª–∏—Ü—É
            gpu_table = pa.Table.from_pandas(results_df)
            self.client.insert_arrow('temp_gpu_results', gpu_table)
            
            # –†–ï–í–û–õ–Æ–¶–ò–û–ù–ù–û–ï –æ–±–æ–≥–∞—â–µ–Ω–∏–µ —á–µ—Ä–µ–∑ Direct Join (FLAT layout)
            # –í–º–µ—Å—Ç–æ –º–µ–¥–ª–µ–Ω–Ω–æ–≥–æ pandas lookup - —Å–≤–µ—Ä—Ö–±—ã—Å—Ç—Ä—ã–π Direct Join
            enriched_insert_sql = f"""
            INSERT INTO helicopter_simulation_results
            SELECT 
                -- GPU —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                g.serialno,
                g.predicted_failure_days,
                g.maintenance_priority,
                g.replacement_recommended,
                g.remaining_resource_pct,
                g.risk_score,
                
                -- DIRECT JOIN –æ–±–æ–≥–∞—â–µ–Ω–∏–µ (O(1) lookup —á–µ—Ä–µ–∑ FLAT layout)
                r.partno,
                p.component_name,      -- Direct Join —Å partno_dict_flat
                r.component_type,
                r.ac_typ,
                r.location,
                r.owner,
                r.condition,
                
                -- –ò—Å—Ö–æ–¥–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã
                r.ll as current_ll,
                r.oh as current_oh,
                r.oh_threshold,
                
                -- –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                '{simulation_id}' as simulation_id,
                now() as simulation_date,
                'FlameGPU_v3.0_DirectJoin' as model_version,
                r.version_date as input_version_date,
                0 as processing_time_ms
                
            FROM temp_gpu_results g
            JOIN helicopter_components_raw r ON g.serialno = r.serialno
            JOIN partno_dict_flat p ON r.partno_id = p.partno_id
            WHERE r.version_date = today()
            SETTINGS join_algorithm='direct'
            """
            
            self.client.command(enriched_insert_sql)
            
            duration = time.time() - start_time
            self.logger.info(f"‚úÖ Direct Join –æ–±–æ–≥–∞—â–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞ {duration:.2f} —Å–µ–∫")
            self.logger.info(f"üöÄ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω FLAT layout Dictionary –¥–ª—è O(1) lookup")
            return True
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ Direct Join –æ–±–æ–≥–∞—â–µ–Ω–∏—è: {e}")
            return False
    

    
    def run_full_pipeline(self, excel_path: str) -> bool:
        """–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞ v3.0 —Å Direct Join"""
        self.logger.info("üöÄ –ó–∞–ø—É—Å–∫ —Ä–µ–≤–æ–ª—é—Ü–∏–æ–Ω–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞ v3.0 —Å Direct Join")
        
        total_start = time.time()
        
        try:
            # 1. –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ ClickHouse
            if not self.connect_clickhouse():
                return False
            
            # 2. –°–æ–∑–¥–∞–Ω–∏–µ Dictionary –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–ª—è Direct Join
            if not self.create_dictionary_tables():
                return False
            
            # 3. –°–æ–∑–¥–∞–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ç–∞–±–ª–∏—Ü
            if not self.create_raw_table() or not self.create_results_table():
                return False
            
            # 4. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Excel
            df, md_dict, md_comp = self.load_excel_data(excel_path)
            
            # 5. –°–æ–∑–¥–∞–Ω–∏–µ –º–∞–ø–ø–∏–Ω–≥–æ–≤ –∏ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ Dictionary –¥–ª—è FLAT layout
            self.create_mappings_and_populate_dictionaries(df, md_dict, md_comp)
            
            # 6. –°–æ–∑–¥–∞–Ω–∏–µ ClickHouse Dictionary –æ–±—ä–µ–∫—Ç–æ–≤ —Å FLAT layout
            if not self.create_clickhouse_dictionaries():
                return False
            
            # 7. –û–±–æ–≥–∞—â–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —á–∏—Å–ª–æ–≤—ã–º–∏ ID
            enriched_df = self.enrich_dataframe(df)
            
            # 8. –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ RAW + –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ GPU
            raw_future = self.parallel_raw_loading(enriched_df)
            cudf_data = self.prepare_gpu_data(enriched_df)
            
            # 9. GPU —Å–∏–º—É–ª—è—Ü–∏—è Flame
            gpu_results = self.simulate_flame_gpu(cudf_data)
            
            # 10. –†–ï–í–û–õ–Æ–¶–ò–û–ù–ù–û–ï –æ–±–æ–≥–∞—â–µ–Ω–∏–µ —á–µ—Ä–µ–∑ Direct Join (~25x –±—ã—Å—Ç—Ä–µ–µ!)
            simulation_id = f"sim_directjoin_{int(time.time())}"
            success = self.enrich_results_with_direct_join(gpu_results, simulation_id)
            
            # 11. –û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ RAW
            raw_future.result()
            
            total_duration = time.time() - total_start
            
            if success:
                self.logger.info("=" * 70)
                self.logger.info("üöÄ –ü–ê–ô–ü–õ–ê–ô–ù v3.0 —Å DIRECT JOIN –ó–ê–í–ï–†–®–ï–ù –£–°–ü–ï–®–ù–û!")
                self.logger.info(f"‚è±Ô∏è –û–±—â–µ–µ –≤—Ä–µ–º—è: {total_duration:.2f} —Å–µ–∫")
                self.logger.info(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∑–∞–ø–∏—Å–µ–π: {len(enriched_df)}")
                self.logger.info(f"üî• GPU —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {len(gpu_results)} –∑–∞–ø–∏—Å–µ–π")
                self.logger.info(f"üöÄ Direct Join: FLAT layout Dictionary (O(1) lookup)")
                self.logger.info("üìà –†–µ–≤–æ–ª—é—Ü–∏–æ–Ω–Ω–æ–µ —É—Å–∫–æ—Ä–µ–Ω–∏–µ –æ–±–æ–≥–∞—â–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤!")
                self.logger.info("=" * 70)
                return True
            else:
                return False
                
        except Exception as e:
            self.logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø–∞–π–ø–ª–∞–π–Ω–∞ v3.0: {e}")
            return False

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    pipeline = OptimizedPipelineV3()
    
    excel_path = "data_input/source_data/Status_Components.xlsx"
    
    if not os.path.exists(excel_path):
        pipeline.logger.error(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {excel_path}")
        return False
    
    return pipeline.run_full_pipeline(excel_path)

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)