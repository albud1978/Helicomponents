#!/usr/bin/env python3
"""
MacroProperty1 Validator - –≤–∞–ª–∏–¥–∞—Ü–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –∑–∞–≥—Ä—É–∑–∫–∏
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –∑–∞–≥—Ä—É–∑–∫–∏ MacroProperty1 —á–µ—Ä–µ–∑ roundtrip —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
"""

import logging
import sys
import os
import json
from typing import Dict, List, Tuple, Any
from datetime import datetime

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ utils
sys.path.append(os.path.join(os.path.dirname(__file__), 'utils'))

from config_loader import get_clickhouse_client
from macroproperty1_loader import MacroProperty1Loader

def setup_logging() -> logging.Logger:
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('logs/macroproperty1_validator.log'),
            logging.StreamHandler(sys.stdout)
        ]
    )
    return logging.getLogger(__name__)

class MacroProperty1Validator:
    """–í–∞–ª–∏–¥–∞—Ç–æ—Ä –∫–∞—á–µ—Å—Ç–≤–∞ –∑–∞–≥—Ä—É–∑–∫–∏ MacroProperty1"""
    
    def __init__(self, client=None):
        self.client = client or get_clickhouse_client()
        self.logger = setup_logging()
        self.validation_table = "test_macroproperty1_roundtrip"
        
    def create_validation_table(self, field_mapping: Dict[str, int], field_types: Dict[int, str]) -> None:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã –¥–ª—è roundtrip –≤–∞–ª–∏–¥–∞—Ü–∏–∏"""
        self.logger.info("üèóÔ∏è –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏...")
        
        try:
            # –°–Ω–∞—á–∞–ª–∞ —É–¥–∞–ª—è–µ–º —Ç–∞–±–ª–∏—Ü—É –µ—Å–ª–∏ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
            self.client.execute(f"DROP TABLE IF EXISTS {self.validation_table}")
            
            # –°–æ–∑–¥–∞–µ–º DDL –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã
            fields_ddl = ["record_id UInt32"]
            
            for field_name, field_id in sorted(field_mapping.items(), key=lambda x: x[1]):
                ch_type = field_types.get(field_id, 'String')
                field_ddl = f"field_{field_id} {ch_type}"
                fields_ddl.append(field_ddl)
                self.logger.info(f"   üìã field_{field_id} ({field_name}): {ch_type}")
            
            create_query = f"""
                CREATE TABLE {self.validation_table} (
                    {', '.join(fields_ddl)}
                ) ENGINE = Memory
            """
            
            self.client.execute(create_query)
            self.logger.info(f"‚úÖ –¢–∞–±–ª–∏—Ü–∞ {self.validation_table} —Å–æ–∑–¥–∞–Ω–∞")
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {e}")
            raise
    
    def export_macroproperty1_to_table(self, macroproperty1: Dict[int, List], 
                                     field_mapping: Dict[str, int]) -> None:
        """–≠–∫—Å–ø–æ—Ä—Ç MacroProperty1 –≤ —Ç–∞–±–ª–∏—Ü—É ClickHouse"""
        self.logger.info("üì§ –≠–∫—Å–ø–æ—Ä—Ç MacroProperty1 –≤ —Ç–∞–±–ª–∏—Ü—É –≤–∞–ª–∏–¥–∞—Ü–∏–∏...")
        
        try:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π
            record_count = len(next(iter(macroproperty1.values())))
            self.logger.info(f"üìä –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º {record_count} –∑–∞–ø–∏—Å–µ–π")
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏
            insert_data = []
            
            for record_id in range(record_count):
                row = [record_id]  # –ù–∞—á–∏–Ω–∞–µ–º —Å record_id
                
                # –î–æ–±–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ field_id –≤ –ø–æ—Ä—è–¥–∫–µ –≤–æ–∑—Ä–∞—Å—Ç–∞–Ω–∏—è
                for field_id in sorted(macroproperty1.keys()):
                    value = macroproperty1[field_id][record_id]
                    row.append(value)
                
                insert_data.append(row)
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –ø–æ–ª–µ–π –¥–ª—è INSERT
            field_list = ["record_id"]
            for field_id in sorted(macroproperty1.keys()):
                field_list.append(f"field_{field_id}")
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –≤—Å—Ç–∞–≤–∫—É
            insert_query = f"INSERT INTO {self.validation_table} ({', '.join(field_list)}) VALUES"
            
            self.client.execute(insert_query, insert_data)
            self.logger.info(f"‚úÖ –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ {len(insert_data)} –∑–∞–ø–∏—Å–µ–π")
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ –≤ —Ç–∞–±–ª–∏—Ü—É: {e}")
            raise
    
    def compare_original_vs_exported(self, field_mapping: Dict[str, int]) -> Dict[str, Any]:
        """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö md_components —Å —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏"""
        self.logger.info("üîç –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Å —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏...")
        
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (–ø–æ—Å–ª–µ–¥–Ω—è—è –≤–µ—Ä—Å–∏—è)
            original_query = """
                SELECT * FROM md_components 
                WHERE (version_date, version_id) = (
                    SELECT version_date, version_id 
                    FROM md_components 
                    ORDER BY version_date DESC, version_id DESC 
                    LIMIT 1
                )
                ORDER BY partno_comp
            """
            original_data = self.client.execute(original_query)
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            exported_query = f"SELECT * FROM {self.validation_table} ORDER BY record_id"
            exported_data = self.client.execute(exported_query)
            
            self.logger.info(f"üìä –ò—Å—Ö–æ–¥–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π: {len(original_data)}")
            self.logger.info(f"üìä –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π: {len(exported_data)}")
            
            # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Ä—è–¥–æ–∫ –ø–æ–ª–µ–π –≤ –∏—Å—Ö–æ–¥–Ω–æ–π —Ç–∞–±–ª–∏—Ü–µ
            original_fields_query = """
                SELECT name, position 
                FROM system.columns 
                WHERE database = 'default' AND table = 'md_components'
                ORDER BY position
            """
            original_field_order = [name for name, pos in self.client.execute(original_fields_query)]
            
            # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Ä—è–¥–æ–∫ –ø–æ–ª–µ–π –≤ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Ç–∞–±–ª–∏—Ü–µ  
            exported_fields_query = f"""
                SELECT name, position 
                FROM system.columns 
                WHERE database = 'default' AND table = '{self.validation_table}'
                ORDER BY position
            """
            exported_field_order = [name for name, pos in self.client.execute(exported_fields_query)]
            
            # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            comparison_results = {
                'total_original_records': len(original_data),
                'total_exported_records': len(exported_data),
                'record_count_match': len(original_data) == len(exported_data),
                'field_comparisons': {},
                'overall_success': True,
                'mismatches': []
            }
            
            # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –ø–æ–ª–µ –≤ –ø–æ–ª–µ
            for field_name, field_id in field_mapping.items():
                if field_name in original_field_order:
                    original_col_idx = original_field_order.index(field_name)
                    exported_field_name = f"field_{field_id}"
                    
                    if exported_field_name in exported_field_order:
                        exported_col_idx = exported_field_order.index(exported_field_name)
                        
                        # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è
                        matches = 0
                        mismatches = 0
                        sample_mismatches = []
                        
                        min_records = min(len(original_data), len(exported_data))
                        
                        for i in range(min_records):
                            original_val = original_data[i][original_col_idx]
                            exported_val = exported_data[i][exported_col_idx]
                            
                            if original_val == exported_val:
                                matches += 1
                            else:
                                mismatches += 1
                                if len(sample_mismatches) < 5:  # –°–æ–±–∏—Ä–∞–µ–º –æ–±—Ä–∞–∑—Ü—ã –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π
                                    sample_mismatches.append({
                                        'record_id': i,
                                        'original': original_val,
                                        'exported': exported_val
                                    })
                        
                        field_success = mismatches == 0
                        comparison_results['field_comparisons'][field_name] = {
                            'field_id': field_id,
                            'matches': matches,
                            'mismatches': mismatches,
                            'success': field_success,
                            'sample_mismatches': sample_mismatches
                        }
                        
                        if not field_success:
                            comparison_results['overall_success'] = False
                            comparison_results['mismatches'].append(field_name)
                        
                        self.logger.info(f"   {'‚úÖ' if field_success else '‚ùå'} {field_name} (field_{field_id}): "
                                       f"{matches} —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π, {mismatches} —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–π")
            
            return comparison_results
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö: {e}")
            raise
    
    def generate_validation_report(self, comparison_results: Dict[str, Any], 
                                 metadata_file: str = None) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏"""
        self.logger.info("üìã –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏...")
        
        try:
            report_lines = []
            report_lines.append("=" * 60)
            report_lines.append("üéØ –û–¢–ß–ï–¢ –í–ê–õ–ò–î–ê–¶–ò–ò MACROPROPERTY1")
            report_lines.append("=" * 60)
            report_lines.append("")
            
            # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            report_lines.append("üìä –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
            report_lines.append(f"   ‚Ä¢ –ò—Å—Ö–æ–¥–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π –≤ md_components: {comparison_results['total_original_records']:,}")
            report_lines.append(f"   ‚Ä¢ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –≤ MacroProperty1: {comparison_results['total_exported_records']:,}")
            report_lines.append(f"   ‚Ä¢ –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∑–∞–ø–∏—Å–µ–π: {'‚úÖ' if comparison_results['record_count_match'] else '‚ùå'}")
            report_lines.append(f"   ‚Ä¢ –û–±—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {'‚úÖ –£–°–ü–ï–®–ù–û' if comparison_results['overall_success'] else '‚ùå –û–®–ò–ë–ö–ò'}")
            report_lines.append("")
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø–æ–ª—è–º
            report_lines.append("üéØ –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–û –ü–û–õ–Ø–ú:")
            
            success_count = 0
            total_fields = len(comparison_results['field_comparisons'])
            
            for field_name, result in comparison_results['field_comparisons'].items():
                status = "‚úÖ" if result['success'] else "‚ùå"
                field_id = result['field_id']
                matches = result['matches']
                mismatches = result['mismatches']
                
                report_lines.append(f"   {status} field_{field_id} ({field_name}): "
                                  f"{matches:,} —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π, {mismatches:,} —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–π")
                
                if not result['success'] and result['sample_mismatches']:
                    report_lines.append(f"      üí• –ü—Ä–∏–º–µ—Ä—ã —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–π:")
                    for sample in result['sample_mismatches'][:3]:
                        report_lines.append(f"         –ó–∞–ø–∏—Å—å {sample['record_id']}: "
                                          f"–∏—Å—Ö–æ–¥–Ω–æ–µ='{sample['original']}', "
                                          f"—ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ='{sample['exported']}'")
                
                if result['success']:
                    success_count += 1
            
            report_lines.append("")
            report_lines.append(f"üìà –ò–¢–û–ì–û: {success_count}/{total_fields} –ø–æ–ª–µ–π –ø—Ä–æ—à–ª–∏ –≤–∞–ª–∏–¥–∞—Ü–∏—é")
            
            # –ü—Ä–æ–±–ª–µ–º—ã
            if comparison_results['mismatches']:
                report_lines.append("")
                report_lines.append("‚ùå –û–ë–ù–ê–†–£–ñ–ï–ù–ù–´–ï –ü–†–û–ë–õ–ï–ú–´:")
                for field_name in comparison_results['mismatches']:
                    report_lines.append(f"   ‚Ä¢ –†–∞—Å—Ö–æ–∂–¥–µ–Ω–∏—è –≤ –ø–æ–ª–µ: {field_name}")
                
                report_lines.append("")
                report_lines.append("üí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
                report_lines.append("   ‚Ä¢ –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É NULL –∑–Ω–∞—á–µ–Ω–∏–π")
                report_lines.append("   ‚Ä¢ –ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç—å —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏—è –≤ —É–∫–∞–∑–∞–Ω–Ω—ã—Ö –ø–æ–ª—è—Ö")
                report_lines.append("   ‚Ä¢ –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö")
            else:
                report_lines.append("")
                report_lines.append("üéâ –û–¢–õ–ò–ß–ù–û! –í—Å–µ –ø–æ–ª—è –ø—Ä–æ—à–ª–∏ –≤–∞–ª–∏–¥–∞—Ü–∏—é —É—Å–ø–µ—à–Ω–æ")
            
            # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã
            if metadata_file and os.path.exists(metadata_file):
                try:
                    with open(metadata_file, 'r', encoding='utf-8') as f:
                        metadata = json.load(f)
                    
                    report_lines.append("")
                    report_lines.append("üìã –ú–ï–¢–ê–î–ê–ù–ù–´–ï –ó–ê–ì–†–£–ó–ö–ò:")
                    report_lines.append(f"   ‚Ä¢ –î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è: {metadata.get('creation_date', 'N/A')}")
                    report_lines.append(f"   ‚Ä¢ –í–µ—Ä—Å–∏—è –¥–∞–Ω–Ω—ã—Ö: {metadata.get('version_date', 'N/A')}")
                    report_lines.append(f"   ‚Ä¢ ID –≤–µ—Ä—Å–∏–∏: {metadata.get('version_id', 'N/A')}")
                    report_lines.append(f"   ‚Ä¢ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –ø–æ–ª–µ–π: {metadata.get('loaded_fields', 'N/A')}")
                except:
                    pass
            
            report_lines.append("")
            report_lines.append("=" * 60)
            
            report_content = "\n".join(report_lines)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
            os.makedirs('temp_data', exist_ok=True)
            report_file = f'temp_data/macroproperty1_validation_report_{datetime.now().strftime("%Y%m%d_%H%M%S")}.txt'
            
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write(report_content)
            
            self.logger.info(f"‚úÖ –û—Ç—á–µ—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_file}")
            
            # –í—ã–≤–æ–¥–∏–º –æ—Ç—á–µ—Ç –≤ –ª–æ–≥
            for line in report_lines:
                self.logger.info(line)
            
            return report_file
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á–µ—Ç–∞: {e}")
            raise
    
    def cleanup_validation_table(self) -> None:
        """–û—á–∏—Å—Ç–∫–∞ —Ç–∞–±–ª–∏—Ü—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏"""
        try:
            self.client.execute(f"DROP TABLE IF EXISTS {self.validation_table}")
            self.logger.info(f"üóëÔ∏è –¢–∞–±–ª–∏—Ü–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ {self.validation_table} —É–¥–∞–ª–µ–Ω–∞")
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {e}")
    
    def validate_macroproperty1(self, macroproperty1: Dict[int, List], 
                              field_mapping: Dict[str, int], 
                              field_types: Dict[int, str],
                              cleanup: bool = True) -> str:
        """–ü–æ–ª–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è MacroProperty1"""
        self.logger.info("üöÄ –ù–∞—á–∞–ª–æ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ MacroProperty1")
        
        try:
            # 1. –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏
            self.create_validation_table(field_mapping, field_types)
            
            # 2. –≠–∫—Å–ø–æ—Ä—Ç MacroProperty1 –≤ —Ç–∞–±–ª–∏—Ü—É
            self.export_macroproperty1_to_table(macroproperty1, field_mapping)
            
            # 3. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
            comparison_results = self.compare_original_vs_exported(field_mapping)
            
            # 4. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞
            report_file = self.generate_validation_report(comparison_results, 
                                                        'temp_data/macroproperty1_metadata.json')
            
            # 5. –û—á–∏—Å—Ç–∫–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            if cleanup:
                self.cleanup_validation_table()
            
            self.logger.info("‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è MacroProperty1 –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
            return report_file
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ MacroProperty1: {e}")
            if cleanup:
                self.cleanup_validation_table()
            raise

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    logger = setup_logging()
    
    try:
        logger.info("üéØ –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ —Ü–∏–∫–ª–∞: –∑–∞–≥—Ä—É–∑–∫–∞ + –≤–∞–ª–∏–¥–∞—Ü–∏—è MacroProperty1")
        
        # 1. –ó–∞–≥—Ä—É–∂–∞–µ–º MacroProperty1
        loader = MacroProperty1Loader()
        macroproperty1 = loader.load_macroproperty1()
        
        # 2. –í–∞–ª–∏–¥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        validator = MacroProperty1Validator()
        
        # –ü–æ–ª—É—á–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏–∑ –∑–∞–≥—Ä—É–∑—á–∏–∫–∞
        field_mapping = loader.stats['field_mapping']
        field_types = loader.stats['data_types']
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏—é
        report_file = validator.validate_macroproperty1(
            macroproperty1, field_mapping, field_types, cleanup=True
        )
        
        logger.info(f"üéâ –ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –∑–∞–≤–µ—Ä—à–µ–Ω! –û—Ç—á–µ—Ç: {report_file}")
        
    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main() 