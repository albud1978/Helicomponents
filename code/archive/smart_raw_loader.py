#!/usr/bin/env python3
"""
–£–º–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ Status_Components.xlsx –≤ RAW —Å–ª–æ–π ClickHouse
Helicopter Component Lifecycle Prediction Project

üöÄ –ù–û–í–ê–Ø –§–£–ù–ö–¶–ò–û–ù–ê–õ–¨–ù–û–°–¢–¨ v2.1:
‚Ä¢ –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –≤—ã–±–æ—Ä —Ä–µ–∂–∏–º–∞ –∑–∞–≥—Ä—É–∑–∫–∏: –í–°–ï –¥–∞–Ω–Ω—ã–µ –∏–ª–∏ –û–ë–û–†–û–¢–ù–´–ï –∞–≥—Ä–µ–≥–∞—Ç—ã (37 –ø–∞—Ä—Ç–Ω–æ–º–µ—Ä–æ–≤)
‚Ä¢ –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø–∞—Ä—Ç–Ω–æ–º–µ—Ä–∞–º –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö  
‚Ä¢ –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö

üîß –û–°–ù–û–í–ù–´–ï –í–û–ó–ú–û–ñ–ù–û–°–¢–ò:
‚Ä¢ Arrow –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ (dtype_backend="pyarrow") –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è transfers
‚Ä¢ –ó–∞—â–∏—Ç–∞ –æ—Ç –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –≤–µ—Ä—Å–∏–æ–Ω–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
‚Ä¢ –ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö
‚Ä¢ –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä—Å–∏–∏ –∏–∑ Excel –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
‚Ä¢ Batch-–∑–∞–≥—Ä—É–∑–∫–∞ —Å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–º –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

üéØ –û–ë–û–†–û–¢–ù–´–ï –ê–ì–†–ï–ì–ê–¢–´ (37 –ø–∞—Ä—Ç–Ω–æ–º–µ—Ä–æ–≤):
–¢–û–ü-37 —Ä–µ–∞–ª—å–Ω—ã—Ö –æ–±–æ—Ä–æ—Ç–Ω—ã—Ö –∞–≥—Ä–µ–≥–∞—Ç–æ–≤ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –∑–∞–ø–∏—Å–µ–π –≤ —Å–∏—Å—Ç–µ–º–µ:
- 8–ê-5104-317-9: 1,135 –∑–∞–ø–∏—Å–µ–π
- –ü-1 3–ü–ú.844.004: 1,039 –∑–∞–ø–∏—Å–µ–π
- 8–ê–¢-2710-00: 1,012 –∑–∞–ø–∏—Å–µ–π
- –ú–£-615–ê –°–ï–†.1 –ò–í–ö–õ.401261.001: 995 –∑–∞–ø–∏—Å–µ–π
- –ò –µ—â–µ 33 —Å–∞–º—ã—Ö –∞–∫—Ç–∏–≤–Ω—ã—Ö –∞–≥—Ä–µ–≥–∞—Ç–∞...
"""
import os
import sys
import pandas as pd
import numpy as np
from clickhouse_driver import Client
import logging
from datetime import datetime, date
import time
import traceback
from pathlib import Path

def setup_logging():
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
    os.makedirs('test_output', exist_ok=True)
    
    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    
    logger = logging.getLogger('smart_loader')
    logger.setLevel(logging.DEBUG)
    
    # –£–±–∏—Ä–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏
    for handler in logger.handlers[:]:
        logger.removeHandler(handler)
    
    # –§–∞–π–ª–æ–≤—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫
    file_handler = logging.FileHandler('test_output/smart_loader.log', mode='w')
    file_handler.setLevel(logging.DEBUG)
    file_handler.setFormatter(formatter)
    
    # –ö–æ–Ω—Å–æ–ª—å–Ω—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    console_handler.setFormatter(formatter)
    
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)
    
    return logger

def load_config():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏–∑ YAML"""
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é –∑–∞–≥—Ä—É–∑–∫–∏
    sys.path.append(str(Path(__file__).parent / 'utils'))
    from config_loader import load_database_config
    return load_database_config()

def connect_clickhouse(config, logger):
    """–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ ClickHouse —Å retry –ª–æ–≥–∏–∫–æ–π"""
    max_retries = 3
    retry_delay = 2
    
    for attempt in range(max_retries):
        try:
            client = Client(
                host=config['host'],
                port=config['port'],
                user=config['user'],
                password=config['password'],
                database=config['database'],
                settings={'strings_encoding': 'utf-8', 'max_threads': 8}
            )
            # –¢–µ—Å—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
            result = client.execute('SELECT 1 as test')
            if result[0][0] == 1:
                logger.info(f"‚úì –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ ClickHouse —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1})")
                return client
        except Exception as e:
            logger.warning(f"–ü–æ–ø—ã—Ç–∫–∞ {attempt + 1} –Ω–µ—É–¥–∞—á–Ω–∞: {e}")
            if attempt < max_retries - 1:
                time.sleep(retry_delay)
            else:
                raise ConnectionError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ ClickHouse –ø–æ—Å–ª–µ {max_retries} –ø–æ–ø—ã—Ç–æ–∫: {e}")

def check_table_exists(client, table_name, logger):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã"""
    try:
        result = client.execute(f"EXISTS TABLE {table_name}")
        exists = result[0][0] == 1
        if exists:
            logger.info(f"üìã –¢–∞–±–ª–∏—Ü–∞ {table_name} —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
            
            # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö
            stats = client.execute(f"""
                SELECT 
                    COUNT(*) as total_rows,
                    COUNT(DISTINCT version_date) as unique_dates,
                    MIN(version_date) as min_date,
                    MAX(version_date) as max_date
                FROM {table_name}
            """)
            
            if stats and stats[0][0] > 0:
                row = stats[0]
                logger.info(f"üìä –°—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ:")
                logger.info(f"  üìÑ –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {row[0]:,}")
                logger.info(f"  üìÖ –í–µ—Ä—Å–∏–π –¥–∞–Ω–Ω—ã—Ö: {row[1]}")
                logger.info(f"  üìÜ –ü–µ—Ä–∏–æ–¥: {row[2]} - {row[3]}")
            else:
                logger.info("üì≠ –¢–∞–±–ª–∏—Ü–∞ –ø—É—Å—Ç–∞")
        else:
            logger.info(f"‚ùå –¢–∞–±–ª–∏—Ü–∞ {table_name} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
        
        return exists
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —Ç–∞–±–ª–∏—Ü—ã: {e}")
        return False

def create_table_if_not_exists(client, table_name, logger):
    """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–Ω–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç"""
    if check_table_exists(client, table_name, logger):
        return True
    
    logger.info(f"üîß –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã {table_name}...")
    
    create_table_sql = """
    CREATE TABLE heli_raw (
        -- –û—Å–Ω–æ–≤–Ω—ã–µ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã
        `partno` Nullable(String),              -- –ü–∞—Ä—Ç–Ω–æ–º–µ—Ä (—á–µ—Ä—Ç–µ–∂–Ω—ã–π –Ω–æ–º–µ—Ä)
        `serialno` Nullable(String),            -- –°–µ—Ä–∏–π–Ω—ã–π –Ω–æ–º–µ—Ä (–∫–∞–∫ —Å—Ç—Ä–æ–∫–∞)
        `ac_typ` Nullable(String),              -- –¢–∏–ø –≤–æ–∑–¥—É—à–Ω–æ–≥–æ —Å—É–¥–Ω–∞
        `location` Nullable(String),            -- –ú–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ/–ø–æ–∑–∏—Ü–∏—è
        
        -- –î–∞—Ç—ã
        `mfg_date` Nullable(Date),              -- –î–∞—Ç–∞ –∏–∑–≥–æ—Ç–æ–≤–ª–µ–Ω–∏—è
        `removal_date` Nullable(Date),          -- –î–∞—Ç–∞ —Å–Ω—è—Ç–∏—è
        `target_date` Nullable(Date),           -- –¶–µ–ª–µ–≤–∞—è –¥–∞—Ç–∞
        
        -- –°–æ—Å—Ç–æ—è–Ω–∏–µ –∏ –≤–ª–∞–¥–µ–Ω–∏–µ
        `condition` Nullable(String),           -- –°–æ—Å—Ç–æ—è–Ω–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞
        `owner` Nullable(String),               -- –í–ª–∞–¥–µ–ª–µ—Ü
        `lease_restricted` Nullable(String),    -- –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –ø–æ –ª–∏–∑–∏–Ω–≥—É
        
        -- –†–µ—Å—É—Ä—Å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (UInt32 –¥–ª—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π GPU –æ–±—Ä–∞–±–æ—Ç–∫–∏)
        `oh` Nullable(UInt32),                  -- –ú–†–† –∞–≥—Ä–µ–≥–∞—Ç–∞ (–º–µ–∂—Ä–µ–º–æ–Ω—Ç–Ω—ã–π —Ä–µ—Å—É—Ä—Å –≤ —á–∞—Å–∞—Ö)
        `oh_threshold` Nullable(UInt32),        -- –ü–æ—Ä–æ–≥ –ú–†–† (–≤ —á–∞—Å–∞—Ö)
        `ll` Nullable(UInt32),                  -- –ù–† –∞–≥—Ä–µ–≥–∞—Ç–∞ (–Ω–∞–∑–Ω–∞—á–µ–Ω–Ω—ã–π —Ä–µ—Å—É—Ä—Å –≤ —á–∞—Å–∞—Ö)
        `sne` Nullable(UInt32),                 -- –ù–∞—Ä–∞–±–æ—Ç–∫–∞ —Å –Ω–∞—á–∞–ª–∞ —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏–∏ (–≤ —á–∞—Å–∞—Ö)
        `ppr` Nullable(UInt32),                 -- –ù–∞—Ä–∞–±–æ—Ç–∫–∞ –ø–æ—Å–ª–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Ä–µ–º–æ–Ω—Ç–∞ (–≤ —á–∞—Å–∞—Ö)
        
        -- –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª–∞
        `version_date` Date DEFAULT today()     -- –î–∞—Ç–∞ –≤–µ—Ä—Å–∏–∏ —Ñ–∞–π–ª–∞ –∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö Excel
        
    ) ENGINE = MergeTree()
    ORDER BY version_date
    PARTITION BY toYYYYMM(version_date)
    SETTINGS index_granularity = 8192
    """
    
    try:
        client.execute(create_table_sql)
        logger.info(f"‚úÖ –¢–∞–±–ª–∏—Ü–∞ {table_name} —Å–æ–∑–¥–∞–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
        return True
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã: {e}")
        return False

def check_data_changes(client, table_name, new_df, version_date, logger):
    """
    –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π –¥–∞–Ω–Ω—ã—Ö –ø–µ—Ä–µ–¥ —Å–æ–∑–¥–∞–Ω–∏–µ–º –Ω–æ–≤–æ–π –≤–µ—Ä—Å–∏–∏
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
    - True: –¥–∞–Ω–Ω—ã–µ –∏–∑–º–µ–Ω–∏–ª–∏—Å—å, –Ω—É–∂–Ω–∞ –Ω–æ–≤–∞—è –≤–µ—Ä—Å–∏—è
    - False: –¥–∞–Ω–Ω—ã–µ –Ω–µ –∏–∑–º–µ–Ω–∏–ª–∏—Å—å, –∑–∞–≥—Ä—É–∑–∫–∞ –Ω–µ –Ω—É–∂–Ω–∞
    """
    logger.info("üîç === –ê–ù–ê–õ–ò–ó –ò–ó–ú–ï–ù–ï–ù–ò–ô –î–ê–ù–ù–´–• ===")
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –≤–µ—Ä—Å–∏—é –¥–∞–Ω–Ω—ã—Ö –∏–∑ ClickHouse
        latest_version_query = f"""
            SELECT version_date, COUNT(*) as record_count
            FROM {table_name} 
            GROUP BY version_date 
            ORDER BY version_date DESC 
            LIMIT 1
        """
        
        latest_version_result = client.execute(latest_version_query)
        
        if not latest_version_result:
            logger.info("üìù –ü–µ—Ä–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ - –¥–∞–Ω–Ω—ã—Ö –≤ —Ç–∞–±–ª–∏—Ü–µ –Ω–µ—Ç")
            return True
        
        latest_version, latest_count = latest_version_result[0]
        logger.info(f"üìä –ü–æ—Å–ª–µ–¥–Ω—è—è –≤–µ—Ä—Å–∏—è: {latest_version} ({latest_count:,} –∑–∞–ø–∏—Å–µ–π)")
        
        # –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –∑–∞–ø–∏—Å–µ–π
        new_count = len(new_df)
        logger.info(f"üìä –ù–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ: {new_count:,} –∑–∞–ø–∏—Å–µ–π")
        
        if new_count != latest_count:
            logger.info(f"‚úÖ –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∑–∞–ø–∏—Å–µ–π: {latest_count:,} ‚Üí {new_count:,}")
            return True
        
        # –î–µ—Ç–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã—Ö —Å—É–º–º –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö –ø–æ–ª–µ–π
        logger.info("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã—Ö —Å—É–º–º –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö –ø–æ–ª–µ–π...")
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∏–º –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è (—Ç–æ–ª—å–∫–æ –∫–ª—é—á–µ–≤—ã–µ –ø–æ–ª—è)
        compare_fields = ['partno', 'serialno', 'sne', 'ppr', 'condition']
        available_compare_fields = [field for field in compare_fields if field in new_df.columns]
        
        if not available_compare_fields:
            logger.warning("‚ö†Ô∏è  –ù–µ—Ç –ø–æ–ª–µ–π –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è - —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –≤–µ—Ä—Å–∏—é")
            return True
        
        logger.info(f"üìã –ü–æ–ª—è –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è: {available_compare_fields}")
        
        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã–µ —Å—É–º–º—ã –∏–∑ ClickHouse –¥–ª—è –ø–æ—Å–ª–µ–¥–Ω–µ–π –≤–µ—Ä—Å–∏–∏
        checksum_fields = []
        for field in available_compare_fields:
            if field in ['sne', 'ppr']:  # –ß–∏—Å–ª–æ–≤—ã–µ –ø–æ–ª—è
                checksum_fields.append(f"round(sum({field}), 2) as sum_{field}")
                checksum_fields.append(f"count(distinct {field}) as distinct_{field}")
            else:  # –°—Ç—Ä–æ–∫–æ–≤—ã–µ –ø–æ–ª—è
                checksum_fields.append(f"count(distinct {field}) as distinct_{field}")
                checksum_fields.append(f"length(groupArray({field})) as count_{field}")
        
        if checksum_fields:
            checksum_query = f"""
                SELECT {', '.join(checksum_fields)}
                FROM {table_name} 
                WHERE version_date = '{latest_version}'
            """
            
            try:
                old_checksums = client.execute(checksum_query)[0]
                logger.info(f"üìä –ö–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã–µ —Å—É–º–º—ã –ë–î: {old_checksums}")
                
                # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã–µ —Å—É–º–º—ã –¥–ª—è –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                new_checksums = []
                for field in available_compare_fields:
                    if field in ['sne', 'ppr'] and field in new_df.columns:
                        # –ß–∏—Å–ª–æ–≤—ã–µ –ø–æ–ª—è
                        field_sum = round(new_df[field].sum(), 2) if not new_df[field].isna().all() else 0
                        field_distinct = new_df[field].nunique()
                        new_checksums.extend([field_sum, field_distinct])
                    elif field in new_df.columns:
                        # –°—Ç—Ä–æ–∫–æ–≤—ã–µ –ø–æ–ª—è  
                        field_distinct = new_df[field].nunique()
                        field_count = len(new_df[field])
                        new_checksums.extend([field_distinct, field_count])
                
                new_checksums = tuple(new_checksums)
                logger.info(f"üìä –ö–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã–µ —Å—É–º–º—ã –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {new_checksums}")
                
                # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã–µ —Å—É–º–º—ã
                if old_checksums == new_checksums:
                    logger.info("‚úÖ –ö–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã–µ —Å—É–º–º—ã —Å–æ–≤–ø–∞–¥–∞—é—Ç - –¥–∞–Ω–Ω—ã–µ –Ω–µ –∏–∑–º–µ–Ω–∏–ª–∏—Å—å")
                    return False
                else:
                    logger.info("üîÑ –ö–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã–µ —Å—É–º–º—ã —Ä–∞–∑–ª–∏—á–∞—é—Ç—Å—è - –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã –∏–∑–º–µ–Ω–µ–Ω–∏—è")
                    
                    # –î–µ—Ç–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–∞–∑–ª–∏—á–∏—è
                    checksum_names = []
                    for field in available_compare_fields:
                        if field in ['sne', 'ppr']:
                            checksum_names.extend([f"sum_{field}", f"distinct_{field}"])
                        else:
                            checksum_names.extend([f"distinct_{field}", f"count_{field}"])
                    
                    for i, (old_val, new_val, name) in enumerate(zip(old_checksums, new_checksums, checksum_names)):
                        if old_val != new_val:
                            logger.info(f"   üîç {name}: {old_val} ‚Üí {new_val}")
                    
                    return True
                    
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã—Ö —Å—É–º–º: {e}")
                logger.info("üí° –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –≤–µ—Ä—Å–∏—é –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏")
                return True
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–π: {e}")
        logger.info("üí° –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –≤–µ—Ä—Å–∏—é –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏")
        return True

def extract_version_date_from_excel(file_path, logger):
    """
    –£–º–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞—Ç—ã –≤–µ—Ä—Å–∏–∏ –∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö Excel —Ñ–∞–π–ª–∞
    
    –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –≤–µ—Ä—Å–∏–∏:
    1. –î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ñ–∞–π–ª–∞ (props.created) - –æ—Å–Ω–æ–≤–Ω–æ–π –∏—Å—Ç–æ—á–Ω–∏–∫
    2. –î–∞—Ç–∞ –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏ (props.modified) - —Ä–µ–∑–µ—Ä–≤–Ω—ã–π
    3. –í—Ä–µ–º—è –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ñ–∞–π–ª–∞ (file mtime) - fallback
    """
    try:
        import openpyxl
        from datetime import datetime
        
        logger.info("üìÖ –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä—Å–∏–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Excel –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö...")
        
        # –û—Ç–∫—Ä—ã–≤–∞–µ–º —Ñ–∞–π–ª –¥–ª—è —á—Ç–µ–Ω–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
        workbook = openpyxl.load_workbook(file_path, read_only=True)
        props = workbook.properties
        
        version_date = None
        source_type = None
        
        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 1: –î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è (–∫–æ–≥–¥–∞ —Ñ–∞–π–ª –±—ã–ª –≤–ø–µ—Ä–≤—ã–µ —Å–æ–∑–¥–∞–Ω)
        if props.created:
            version_date = props.created.date()
            source_type = "Excel —Å–≤–æ–π—Å—Ç–≤–æ 'created'"
            logger.info(f"üìÖ –î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è Excel: {version_date} ({props.created})")
            
        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 2: –î–∞—Ç–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–π –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏ –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
        elif props.modified:
            version_date = props.modified.date()
            source_type = "Excel —Å–≤–æ–π—Å—Ç–≤–æ 'modified'"
            logger.info(f"üìÖ –î–∞—Ç–∞ –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏ Excel: {version_date} ({props.modified})")
            
        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 3: –í—Ä–µ–º—è –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ñ–∞–π–ª–∞ –≤ –û–°
        else:
            import os
            file_mtime = os.path.getmtime(file_path)
            version_date = datetime.fromtimestamp(file_mtime).date()
            source_type = "–≤—Ä–µ–º—è –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ñ–∞–π–ª–∞ –û–°"
            logger.warning(f"‚ö†Ô∏è  Excel –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã")
            logger.info(f"üìÖ –í—Ä–µ–º—è –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ñ–∞–π–ª–∞: {version_date}")
        
        workbook.close()
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        try:
            import os
            file_size = os.path.getsize(file_path)
            file_mtime = datetime.fromtimestamp(os.path.getmtime(file_path))
            logger.info(f"üìã –§–∞–π–ª: {os.path.basename(file_path)}")
            logger.info(f"üìè –†–∞–∑–º–µ—Ä: {file_size:,} –±–∞–π—Ç")
            logger.info(f"üïê –ú–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏—è –û–°: {file_mtime}")
            logger.info(f"üéØ –ò—Å—Ç–æ—á–Ω–∏–∫ –≤–µ—Ä—Å–∏–∏: {source_type}")
        except:
            pass
        
        return version_date
        
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö Excel: {e}")
        
        # Fallback –∫ –¥–∞—Ç–µ —Ñ–∞–π–ª–∞
        try:
            import os
            from datetime import datetime
            file_mtime = os.path.getmtime(file_path)
            version_date = datetime.fromtimestamp(file_mtime).date()
            logger.info(f"üìÖ Fallback: –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Ä–µ–º—è –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ñ–∞–π–ª–∞: {version_date}")
            return version_date
        except Exception as fallback_error:
            from datetime import datetime
            logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤–µ—Ä—Å–∏–∏: {fallback_error}")
            # –ü–æ—Å–ª–µ–¥–Ω–∏–π fallback - —Å–µ–≥–æ–¥–Ω—è—à–Ω—è—è –¥–∞—Ç–∞
            version_date = datetime.now().date()
            logger.warning(f"üö® –≠–∫—Å—Ç—Ä–µ–Ω–Ω—ã–π fallback: –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–µ–≥–æ–¥–Ω—è—à–Ω—é—é –¥–∞—Ç—É: {version_date}")
            return version_date

def load_excel_data(file_path, logger):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Excel —Ñ–∞–π–ª–∞ —Å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –ø–∞—Ä—Å–∏–Ω–≥–æ–º"""
    logger.info(f"üìñ –ó–∞–≥—Ä—É–∑–∫–∞ Excel —Ñ–∞–π–ª–∞: {file_path}")
    
    try:
        # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —á—Ç–µ–Ω–∏–µ —Å Arrow backend –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º dtype_backend="pyarrow" - —Å—Ç–æ–ª–±—Ü—ã —Å—Ä–∞–∑—É —Å—Ç–∞–Ω—É—Ç Arrow-–º–∞—Å—Å–∏–≤–∞–º–∏
            df = pd.read_excel(
                file_path, 
                header=0, 
                engine='openpyxl',
                dtype_backend="pyarrow"  # üöÄ Arrow backend –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
            )
            logger.info(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Å—Ç—Ä–æ–∫: {len(df):,}")
            logger.info(f"üìä –°—Ç–æ–ª–±—Ü–æ–≤: {len(df.columns)}")
            logger.info(f"‚ö° –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è Arrow backend –¥–ª—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")
            
        except Exception as e:
            logger.warning(f"Fallback –∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º—É —á—Ç–µ–Ω–∏—é –±–µ–∑ Arrow backend: {e}")
            df = pd.read_excel(file_path, header=0)
            logger.info(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Å—Ç—Ä–æ–∫: {len(df):,}")
            logger.info(f"üìä –°—Ç–æ–ª–±—Ü–æ–≤: {len(df.columns)}")
        
        return df
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ Excel: {e}")
        raise

def get_repairable_partno_list():
    """
    –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ —á–∏—Ç–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∞–≥—Ä–µ–≥–∞—Ç–æ–≤ –∏–∑ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∞ MD_Components.xlsx
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∞–∫—Ç—É–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫ –ø–∞—Ä—Ç–Ω–æ–º–µ—Ä–æ–≤ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö
    
    Returns:
        list: –°–ø–∏—Å–æ–∫ –ø–∞—Ä—Ç–Ω–æ–º–µ—Ä–æ–≤ –∏–∑ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∞ MD_Components
    """
    import os
    from pathlib import Path
    
    try:
        # –ü—É—Ç—å –∫ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫—É MD_Components
        md_components_path = Path('data_input/master_data/MD_–°omponents.xlsx')
        
        if not md_components_path.exists():
            print(f"‚ö†Ô∏è –§–∞–π–ª {md_components_path} –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback —Å–ø–∏—Å–æ–∫")
            # Fallback –∫ –æ—Å–Ω–æ–≤–Ω—ã–º –∞–≥—Ä–µ–≥–∞—Ç–∞–º –µ—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω
            return [
                '8–ê–¢-2710-00', '8–ê–¢.2710.000', '–ö–ê–£-115–ê–ú', '–ö–ê–£-30–ë', 
                '–ê–ò-9–í', '8-1930-000 –°–ï–†.02', '8-1960-000', '8-1950-000'
            ]
        
        # –ß–∏—Ç–∞–µ–º MD_Components.xlsx
        df = pd.read_excel(
            md_components_path, 
            sheet_name='–ê–≥—Ä–µ–≥–∞—Ç—ã', 
            header=7,  # –†—É—Å—Å–∫–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –Ω–∞ —Å—Ç—Ä–æ–∫–µ 8
            engine='openpyxl'
        )
        
        # –û—á–∏—â–∞–µ–º –æ—Ç –ø—É—Å—Ç—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –∏ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
        df_clean = df.dropna(subset=['–ß–µ—Ä—Ç–µ–∂–Ω—ã–π –Ω–æ–º–µ—Ä'])
        df_clean = df_clean[df_clean['–ß–µ—Ä—Ç–µ–∂–Ω—ã–π –Ω–æ–º–µ—Ä'] != 'partno']  # –£–±–∏—Ä–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
        
        partnos_raw = df_clean['–ß–µ—Ä—Ç–µ–∂–Ω—ã–π –Ω–æ–º–µ—Ä'].dropna().unique()
        
        # –†–∞–∑–≤–æ—Ä–∞—á–∏–≤–∞–µ–º –º–Ω–æ–≥–æ—Å—Ç—Ä–æ—á–Ω—ã–µ –ø–∞—Ä—Ç–Ω–æ–º–µ—Ä–∞ (ctrl+enter –≤ Excel)
        all_partnos = []
        for partno in partnos_raw:
            if isinstance(partno, str):
                # –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ –ø–µ—Ä–µ–Ω–æ—Å–∞–º —Å—Ç—Ä–æ–∫ (\n)
                subpartnos = [p.strip() for p in partno.split('\n') if p.strip()]
                all_partnos.extend(subpartnos)
            else:
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –Ω–µ—Å—Ç—Ä–æ–∫–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
                all_partnos.append(str(partno).strip())
        
        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ–º
        unique_partnos = sorted(list(set(all_partnos)))
        
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(unique_partnos)} –ø–∞—Ä—Ç–Ω–æ–º–µ—Ä–æ–≤ –∏–∑ MD_Components.xlsx")
        print(f"üìã –ü–µ—Ä–≤—ã–µ 5: {unique_partnos[:5]}")
        
        return unique_partnos
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è MD_Components.xlsx: {e}")
        print("üîÑ –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∑–µ—Ä–≤–Ω—ã–π —Å–ø–∏—Å–æ–∫ –∞–≥—Ä–µ–≥–∞—Ç–æ–≤")
        # –†–µ–∑–µ—Ä–≤–Ω—ã–π —Å–ø–∏—Å–æ–∫ –æ—Å–Ω–æ–≤–Ω—ã—Ö –∞–≥—Ä–µ–≥–∞—Ç–æ–≤
        return [
            '8–ê–¢-2710-00', '8–ê–¢.2710.000', '–ö–ê–£-115–ê–ú', '–ö–ê–£-30–ë', '–ê–ò-9–í',
            '8-1930-000 –°–ï–†.02', '8-1960-000', '8-1950-000', '8-3904-000 –°–ï–†–ò–Ø 06',
            '246-3904-000 –°–ï–†–ò–ò 01', '8-3922-00', '246-3925-00', '–†–ê-60–ë',
            '246-1517-000', '8–ú-1517-000', '8–ê-1515-000', '8–ú-1515-000',
            '8–ê-1516-000', '8–ú-1516-000', '8–ê-6314-00', '8–ê–¢.6314.000'
        ]

def filter_by_repairable_partnos(df, logger, enable_filter=False):
    """
    –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –ø–æ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–º—É —Å–ø–∏—Å–∫—É –∞–≥—Ä–µ–≥–∞—Ç–æ–≤ –∏–∑ MD_Components.xlsx
    
    Args:
        df: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
        logger: –ª–æ–≥–≥–µ—Ä
        enable_filter: True –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏, False –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö
        
    Returns:
        –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π DataFrame
    """
    if not enable_filter:
        logger.info("üîÑ –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –ø–∞—Ä—Ç–Ω–æ–º–µ—Ä–∞–º –û–¢–ö–õ–Æ–ß–ï–ù–ê - –∑–∞–≥—Ä—É–∂–∞–µ–º –í–°–ï –¥–∞–Ω–Ω—ã–µ")
        return df
    
    if 'partno' not in df.columns:
        logger.warning("‚ö†Ô∏è  –°—Ç–æ–ª–±–µ—Ü 'partno' –Ω–µ –Ω–∞–π–¥–µ–Ω - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é")
        return df
    
    repairable_partnos = get_repairable_partno_list()
    logger.info(f"üéØ –í–ö–õ–Æ–ß–ï–ù–ê —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ {len(repairable_partnos)} –æ–±–æ—Ä–æ—Ç–Ω—ã–º –∞–≥—Ä–µ–≥–∞—Ç–∞–º")
    
    # –ò—Å—Ö–æ–¥–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π
    original_count = len(df)
    logger.info(f"üìä –ò—Å—Ö–æ–¥–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π: {original_count:,}")
    
    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è
    filtered_df = df[df['partno'].isin(repairable_partnos)].copy()
    filtered_count = len(filtered_df)
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
    logger.info(f"üìä –ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {filtered_count:,} –∑–∞–ø–∏—Å–µ–π")
    if original_count > 0:
        filter_percentage = (filtered_count / original_count) * 100
        logger.info(f"üìä –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ: {filter_percentage:.1f}% –æ—Ç –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
    
    # –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –Ω–∞–π–¥–µ–Ω–Ω—ã–º –ø–∞—Ä—Ç–Ω–æ–º–µ—Ä–∞–º
    if filtered_count > 0:
        found_partnos = filtered_df['partno'].unique()
        logger.info(f"üîç –ù–∞–π–¥–µ–Ω–æ {len(found_partnos)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–∞—Ä—Ç–Ω–æ–º–µ—Ä–æ–≤ –∏–∑ {len(repairable_partnos)} –≤ —Å–ø–∏—Å–∫–µ:")
        
        partno_counts = filtered_df['partno'].value_counts()
        for partno in sorted(found_partnos):
            count = partno_counts[partno]
            logger.info(f"   üì¶ {partno}: {count:,} –∑–∞–ø–∏—Å–µ–π")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–∞–∫–∏–µ –ø–∞—Ä—Ç–Ω–æ–º–µ—Ä–∞ –ù–ï –Ω–∞–π–¥–µ–Ω—ã
        missing_partnos = set(repairable_partnos) - set(found_partnos)
        if missing_partnos:
            logger.info(f"‚ùå –ù–ï –Ω–∞–π–¥–µ–Ω–æ {len(missing_partnos)} –æ–±–æ—Ä–æ—Ç–Ω—ã—Ö –∞–≥—Ä–µ–≥–∞—Ç–æ–≤:")
            for partno in sorted(missing_partnos):
                logger.info(f"   üö´ {partno}")
    else:
        logger.warning("‚ö†Ô∏è  –ù–ò –û–î–ò–ù –∏–∑ –æ–±–æ—Ä–æ—Ç–Ω—ã—Ö –∞–≥—Ä–µ–≥–∞—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –¥–∞–Ω–Ω—ã—Ö!")
        logger.info("üí° –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å —Å–ø–∏—Å–∫–∞ –ø–∞—Ä—Ç–Ω–æ–º–µ—Ä–æ–≤")
    
    return filtered_df

def prepare_data_for_clickhouse(df, version_date, logger, enable_partno_filter=False):
    """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –≤ ClickHouse —Å Arrow –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏"""
    logger.info("üîß –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è ClickHouse...")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ª–∏ Arrow backend
    is_arrow_backend = hasattr(df.dtypes.iloc[0], '__array_function__') if len(df.dtypes) > 0 else False
    if is_arrow_backend:
        logger.info("‚ö° –û–±–Ω–∞—Ä—É–∂–µ–Ω Arrow backend - –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è")
    
    # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é DataFrame
    result_df = df.copy()
    
    # –ù–û–í–ê–Ø –§–£–ù–ö–¶–ò–û–ù–ê–õ–¨–ù–û–°–¢–¨: –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –æ–±–æ—Ä–æ—Ç–Ω—ã–º –∞–≥—Ä–µ–≥–∞—Ç–∞–º
    result_df = filter_by_repairable_partnos(result_df, logger, enable_partno_filter)
    
    # –¶–µ–ª–µ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ (—Ç–µ —á—Ç–æ –µ—Å—Ç—å –≤ –¥–∞–Ω–Ω—ã—Ö)
    target_columns = [
        'partno', 'serialno', 'ac_typ', 'location',
        'mfg_date', 'removal_date', 'target_date', 
        'condition', 'owner', 'lease_restricted',
        'oh', 'oh_threshold', 'll', 'sne', 'ppr'
    ]
    
    # –õ–æ–≥–∏—Ä—É–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
    logger.info(f"üîç –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –≤ Excel: {list(df.columns)}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∫–∏–µ —Ü–µ–ª–µ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–æ—Å—Ç—É–ø–Ω—ã –≤ —Ñ–∞–π–ª–µ
    available_target_columns = [col for col in target_columns if col in result_df.columns]
    logger.info(f"üìã –î–æ—Å—Ç—É–ø–Ω—ã–µ —Ü–µ–ª–µ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {available_target_columns}")
    
    # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ (–∫–æ—Ç–æ—Ä—ã–µ –µ—Å—Ç—å)
    result_df = result_df[available_target_columns].copy()
    
    # –î–æ–±–∞–≤–ª—è–µ–º version_date
    result_df['version_date'] = version_date
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞—Ç –¥–ª—è ClickHouse (–≤—Å–µ–≥–¥–∞ –Ω—É–∂–Ω–∞)
    date_columns = ['mfg_date', 'removal_date', 'target_date']
    for col in date_columns:
        if col in result_df.columns:
            result_df[col] = pd.to_datetime(result_df[col], dayfirst=True, errors='coerce')
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ date –¥–ª—è ClickHouse
            result_df[col] = result_df[col].dt.date
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–Ω—ã—Ö –ø–æ–ª–µ–π (UInt32 –¥–ª—è GPU –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏)
    resource_columns = ['oh', 'oh_threshold', 'll', 'sne', 'ppr']
    for col in resource_columns:
        if col in result_df.columns:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —á–∏—Å–ª–∞, –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –æ–±–Ω—É–ª—è–µ–º
            numeric_series = pd.to_numeric(result_df[col], errors='coerce')
            # –ó–∞–º–µ–Ω—è–µ–º –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ 0 (—Ä–µ—Å—É—Ä—Å –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º)
            numeric_series = numeric_series.clip(lower=0)
            # –ü—Ä–∏–≤–æ–¥–∏–º –∫ UInt32 –¥–ª—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π GPU –æ–±—Ä–∞–±–æ—Ç–∫–∏
            result_df[col] = numeric_series.astype('UInt32')
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç—Ä–æ–∫–æ–≤—ã—Ö –ø–æ–ª–µ–π –¥–ª—è ClickHouse
    string_columns = ['partno', 'serialno', 'ac_typ', 'location', 'condition', 'owner', 'lease_restricted']
    for col in string_columns:
        if col in result_df.columns:
            # –ü—Ä–∏–≤–æ–¥–∏–º –∫ —Å—Ç—Ä–æ–∫–∞–º –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º None
            result_df[col] = result_df[col].astype(str)
            result_df[col] = result_df[col].replace('nan', None)
    
    # –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ NaN –¥–ª—è ClickHouse
    result_df = result_df.replace({np.nan: None, pd.NaT: None})
    
    if is_arrow_backend:
        logger.info("üöÄ Arrow backend —É—Å–∫–æ—Ä—è–µ—Ç –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –¥–ª—è ClickHouse")
    
    logger.info(f"‚úÖ –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {len(result_df):,} –∑–∞–ø–∏—Å–µ–π")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ö–µ–º—É –¥–∞–Ω–Ω—ã—Ö
    logger.info("üìã –°—Ö–µ–º–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:")
    for col in result_df.columns:
        logger.info(f"  {col}: {result_df[col].dtype}")
    
    return result_df

def validate_data_quality(df, logger) -> bool:
    """
    –ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö –ø–µ—Ä–µ–¥ –∑–∞–≥—Ä—É–∑–∫–æ–π
    """
    logger.info("üîç === –í–ê–õ–ò–î–ê–¶–ò–Ø –ö–ê–ß–ï–°–¢–í–ê –î–ê–ù–ù–´–• ===")
    
    quality_passed = True
    
    # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ DataFrame
    if df.empty:
        logger.error("‚ùå DataFrame –ø—É—Å—Ç–æ–π!")
        return False
    
    logger.info(f"üìä –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä DataFrame: {len(df):,} –∑–∞–ø–∏—Å–µ–π")
    
    # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø–æ–ª–µ–π
    critical_fields = ['partno', 'serialno', 'ac_typ']
    for field in critical_fields:
        if field not in df.columns:
            logger.error(f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ –ø–æ–ª–µ: {field}")
            quality_passed = False
        else:
            null_count = df[field].isnull().sum()
            null_percent = (null_count / len(df)) * 100
            
            if null_percent > 50:  # –ë–æ–ª–µ–µ 50% –ø—É—Å—Ç—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π - –∫—Ä–∏—Ç–∏—á–Ω–æ
                logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ –ø–æ–ª–µ {field}: {null_percent:.1f}% –ø—É—Å—Ç—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π")
                quality_passed = False
            elif null_percent > 10:  # –ë–æ–ª–µ–µ 10% - –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ
                logger.warning(f"‚ö†Ô∏è  –ü–æ–ª–µ {field}: {null_percent:.1f}% –ø—É—Å—Ç—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π")
            else:
                logger.info(f"‚úÖ –ü–æ–ª–µ {field}: {null_percent:.1f}% –ø—É—Å—Ç—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π")
    
    # 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
    duplicate_cols = ['partno', 'serialno']
    if all(col in df.columns for col in duplicate_cols):
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ –ø–∞—Ä—Ç–Ω–æ–º–µ—Ä+—Å–µ—Ä–∏–π–Ω—ã–π
        subset_df = df.dropna(subset=duplicate_cols)
        if len(subset_df) > 0:
            duplicates = subset_df.duplicated(subset=duplicate_cols, keep=False)
            duplicate_count = duplicates.sum()
            
            if duplicate_count > 0:
                duplicate_percent = (duplicate_count / len(df)) * 100
                logger.warning(f"‚ö†Ô∏è  –ù–∞–π–¥–µ–Ω—ã –¥—É–±–ª–∏–∫–∞—Ç—ã partno+serialno: {duplicate_count} ({duplicate_percent:.1f}%)")
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
                duplicate_examples = subset_df[duplicates][duplicate_cols].head(5)
                logger.warning(f"üìã –ü—Ä–∏–º–µ—Ä—ã –¥—É–±–ª–∏–∫–∞—Ç–æ–≤:")
                for _, row in duplicate_examples.iterrows():
                    logger.warning(f"   {row['partno']} + {row['serialno']}")
            else:
                logger.info("‚úÖ –î—É–±–ª–∏–∫–∞—Ç—ã –ø–æ partno+serialno –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
    
    # 4. –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤ —Ä–µ—Å—É—Ä—Å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    resource_fields = ['oh', 'oh_threshold', 'll', 'sne', 'ppr']
    for field in resource_fields:
        if field in df.columns:
            numeric_data = pd.to_numeric(df[field], errors='coerce')
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
            negative_count = (numeric_data < 0).sum()
            if negative_count > 0:
                logger.warning(f"‚ö†Ô∏è  –ü–æ–ª–µ {field}: {negative_count} –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π (–±–æ–ª—å—à–µ 50,000 —á–∞—Å–æ–≤ = ~6 –ª–µ—Ç –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–π —Ä–∞–±–æ—Ç—ã)
            extreme_count = (numeric_data > 50000).sum()
            if extreme_count > 0:
                logger.warning(f"‚ö†Ô∏è  –ü–æ–ª–µ {field}: {extreme_count} —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π (>50,000 —á–∞—Å–æ–≤)")
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –Ω–µ–Ω—É–ª–µ–≤—ã–º –∑–Ω–∞—á–µ–Ω–∏—è–º
            non_zero_data = numeric_data[numeric_data > 0]
            if len(non_zero_data) > 0:
                logger.info(f"üìä –ü–æ–ª–µ {field}: –º–∏–Ω={non_zero_data.min():.0f}, –º–∞–∫—Å={non_zero_data.max():.0f}, –º–µ–¥–∏–∞–Ω–∞={non_zero_data.median():.0f}")
    
    # 5. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∏–ø–æ–≤ –í–°
    if 'ac_typ' in df.columns:
        unique_ac_types = df['ac_typ'].dropna().unique()
        logger.info(f"‚úàÔ∏è  –¢–∏–ø—ã –í–° –≤ –¥–∞–Ω–Ω—ã—Ö ({len(unique_ac_types)}): {', '.join(unique_ac_types)}")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ —Ç–∏–ø—ã –í–°
        known_types = ['–ú–∏-26', '–ú–ò26–¢', '–ú–∏-17', '–ú–∏-8–¢', '–ö–∞-32', 'AS-350', '350B3', 'AS-355', '355NP', 'R-44']
        unknown_types = [t for t in unique_ac_types if t not in known_types]
        if unknown_types:
            logger.warning(f"‚ö†Ô∏è  –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ —Ç–∏–ø—ã –í–°: {', '.join(unknown_types)}")
    
    # 6. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏–π
    if 'condition' in df.columns:
        unique_conditions = df['condition'].dropna().unique()
        logger.info(f"üîß –°–æ—Å—Ç–æ—è–Ω–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ ({len(unique_conditions)}): {', '.join(unique_conditions)}")
        
        known_conditions = ['–ò–°–ü–†–ê–í–ù–´–ô', '–ù–ï–ò–°–ü–†–ê–í–ù–´–ô', '–î–û–ù–û–†', '–°–ù–Ø–¢ –ó–ê–ö–ê–ó–ß–ò–ö–û–ú', '–°–ù–Ø–¢', '–ù–ï –£–°–¢–ê–ù–û–í–õ–ï–ù', '–ü–û–°–¢–ê–í–ö–ê']
        unknown_conditions = [c for c in unique_conditions if c not in known_conditions]
        if unknown_conditions:
            logger.warning(f"‚ö†Ô∏è  –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è: {', '.join(unknown_conditions)}")
    
    # 7. –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞—Ç
    date_fields = ['mfg_date', 'removal_date', 'target_date']
    for field in date_fields:
        if field in df.columns:
            # –ü–æ–ø—ã—Ç–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –≤ –¥–∞—Ç—ã
            try:
                date_series = pd.to_datetime(df[field], errors='coerce')
                null_dates = date_series.isnull().sum()
                valid_dates = len(date_series) - null_dates
                
                if valid_dates > 0:
                    min_date = date_series.min()
                    max_date = date_series.max()
                    logger.info(f"üìÖ –ü–æ–ª–µ {field}: {valid_dates} –≤–∞–ª–∏–¥–Ω—ã—Ö –¥–∞—Ç ({min_date.date()} - {max_date.date()})")
                    
                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –±—É–¥—É—â–∏–µ –¥–∞—Ç—ã (–∫—Ä–æ–º–µ target_date)
                    if field != 'target_date':
                        future_dates = (date_series > pd.Timestamp.now()).sum()
                        if future_dates > 0:
                            logger.warning(f"‚ö†Ô∏è  –ü–æ–ª–µ {field}: {future_dates} –¥–∞—Ç –≤ –±—É–¥—É—â–µ–º")
                else:
                    logger.warning(f"‚ö†Ô∏è  –ü–æ–ª–µ {field}: –Ω–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –¥–∞—Ç")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞—Ç –≤ –ø–æ–ª–µ {field}: {e}")
    
    # 8. –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
    if quality_passed:
        logger.info("‚úÖ === –î–ê–ù–ù–´–ï –ü–†–û–®–õ–ò –í–ê–õ–ò–î–ê–¶–ò–Æ –ö–ê–ß–ï–°–¢–í–ê ===")
    else:
        logger.error("‚ùå === –î–ê–ù–ù–´–ï –ù–ï –ü–†–û–®–õ–ò –í–ê–õ–ò–î–ê–¶–ò–Æ –ö–ê–ß–ï–°–¢–í–ê ===")
    
    return quality_passed

def get_file_path(logger) -> str:
    """–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –≤—ã–±–æ—Ä —Ñ–∞–π–ª–∞ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏"""
    logger.info("üìÅ === –í–´–ë–û–† –§–ê–ô–õ–ê –î–õ–Ø –ó–ê–ì–†–£–ó–ö–ò ===")
    
    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É
    default_file = 'data_input/source_data/Status_Components.xlsx'
    
    print(f"\nüìÇ –§–ê–ô–õ –î–õ–Ø –ó–ê–ì–†–£–ó–ö–ò:")
    print(f"1Ô∏è‚É£  –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ñ–∞–π–ª: {default_file}")
    print(f"2Ô∏è‚É£  –£–∫–∞–∑–∞—Ç—å –¥—Ä—É–≥–æ–π —Ñ–∞–π–ª")
    print(f"3Ô∏è‚É£  –û—Ç–º–µ–Ω–∞")
    
    while True:
        try:
            choice = input(f"\n–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª (1-3): ").strip()
            if choice == '1':
                if os.path.exists(default_file):
                    logger.info(f"‚úÖ –í—ã–±—Ä–∞–Ω —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ñ–∞–π–ª: {default_file}")
                    return default_file
                else:
                    logger.error(f"‚ùå –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {default_file}")
                    print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω. –í—ã–±–µ—Ä–∏—Ç–µ –¥—Ä—É–≥–æ–π –≤–∞—Ä–∏–∞–Ω—Ç.")
                    continue
            elif choice == '2':
                custom_path = input(f"–í–≤–µ–¥–∏—Ç–µ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É: ").strip()
                if os.path.exists(custom_path):
                    logger.info(f"‚úÖ –í—ã–±—Ä–∞–Ω —Ñ–∞–π–ª: {custom_path}")
                    return custom_path
                else:
                    logger.error(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {custom_path}")
                    print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.")
                    continue
            elif choice == '3':
                logger.info("‚ùå –û–ø–µ—Ä–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
                return None
            else:
                print("‚ùå –í–≤–µ–¥–∏—Ç–µ 1, 2 –∏–ª–∏ 3")
        except KeyboardInterrupt:
            print("\nüëã –û–ø–µ—Ä–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
            return None

def batch_insert_to_clickhouse(client, table_name: str, df: pd.DataFrame, logger):
    """–ë–∞—Ç—á–µ–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –≤ ClickHouse —Å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–º –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
    logger.info("üöÄ === –ë–ê–¢–ß–ï–í–ê–Ø –ó–ê–ì–†–£–ó–ö–ê –í CLICKHOUSE ===")
    
    total_start_time = time.time()
    batch_size = 5000
    total_rows = len(df)
    
    success_count = 0
    total_records = 0
    
    logger.info(f"üìä –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–≥—Ä—É–∑–∫–∏:")
    logger.info(f"   üìÑ –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {total_rows:,}")
    logger.info(f"   üì¶ –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: {batch_size:,}")
    logger.info(f"   üî¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∞—Ç—á–µ–π: {(total_rows + batch_size - 1) // batch_size}")
    
    for i in range(0, total_rows, batch_size):
        batch = df.iloc[i:i + batch_size]
        batch_num = (i // batch_size) + 1
        total_batches = (total_rows + batch_size - 1) // batch_size
        
        start_time = time.time()
        
        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º DataFrame –≤ —Å–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π
            # Arrow backend –º–æ–∂–µ—Ç —É—Å–∫–æ—Ä–∏—Ç—å —ç—Ç–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ
            data_tuples = [tuple(row) for row in batch.values]
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º INSERT
            client.execute(f'INSERT INTO {table_name} VALUES', data_tuples)
            
            batch_time = time.time() - start_time
            rows_per_sec = len(data_tuples) / batch_time if batch_time > 0 else 0
            
            logger.info(f"‚úÖ –ë–∞—Ç—á {batch_num}/{total_batches}: {len(data_tuples):,} –∑–∞–ø–∏—Å–µ–π –∑–∞ {batch_time:.2f}—Å ({rows_per_sec:,.0f} –∑–∞–ø–∏—Å–µ–π/—Å–µ–∫)")
            
            success_count += 1
            total_records += len(batch)
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –±–∞—Ç—á–∞ {batch_num}: {e}")
            raise  # –ü—Ä–µ—Ä—ã–≤–∞–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–∏ –æ—à–∏–±–∫–µ
    
    # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    total_time = time.time() - total_start_time
    
    if success_count == (total_rows + batch_size - 1) // batch_size:
        logger.info(f"üéâ === –ë–ê–¢–ß–ï–í–ê–Ø –ó–ê–ì–†–£–ó–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê –£–°–ü–ï–®–ù–û ===")
        logger.info(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –±–∞—Ç—á–µ–π: {success_count}")
        logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: {total_records:,}")
        logger.info(f"‚è±Ô∏è  –û–±—â–µ–µ –≤—Ä–µ–º—è: {total_time:.2f} —Å–µ–∫—É–Ω–¥")
        logger.info(f"‚ö° –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {total_records/total_time:,.0f} –∑–∞–ø–∏—Å–µ–π/—Å–µ–∫")
        logger.info(f"üöÄ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã Arrow –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏: dtype_backend='pyarrow'")
    else:
        logger.error(f"üí• –ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —Å –æ—à–∏–±–∫–∞–º–∏!")
        logger.error(f"‚ùå –£—Å–ø–µ—à–Ω—ã—Ö –±–∞—Ç—á–µ–π: {success_count}")
        raise Exception("–ë–∞—Ç—á–µ–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –Ω–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ —Å –≤—ã–±–æ—Ä–æ–º —Ä–µ–∂–∏–º–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
    try:
        logger = setup_logging()
        logger.info("üöÄ === SMART RAW LOADER v2.1 ===")
        logger.info("üìä Helicopter Component Lifecycle Prediction Project")
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        config = load_config()
        logger.info("‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        
        # –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –≤—ã–±–æ—Ä —Ñ–∞–π–ª–∞
        file_path = get_file_path(logger)
        if not file_path:
            return
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞
        if not os.path.exists(file_path):
            logger.error(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
            return
        
        # === –ù–û–í–´–ô –í–´–ë–û–† –†–ï–ñ–ò–ú–ê –û–ë–†–ê–ë–û–¢–ö–ò ===
        print("\nüéØ –†–ï–ñ–ò–ú –û–ë–†–ê–ë–û–¢–ö–ò –î–ê–ù–ù–´–•:")
        print("1Ô∏è‚É£  –ó–∞–≥—Ä—É–∑–∫–∞ –≤ ClickHouse RAW —Å–ª–æ–π (–∫–∞–∫ —Ä–∞–Ω—å—à–µ)")
        print("2Ô∏è‚É£  –°–æ–∑–¥–∞–Ω–∏–µ DataFrame —Å —Ü–∏—Ñ—Ä–æ–≤–∏–∑–∞—Ü–∏–µ–π –ø–æ–ª–µ–π (–Ω–æ–≤–æ–µ)")
        print("3Ô∏è‚É£  –û–±–∞ —Ä–µ–∂–∏–º–∞: DataFrame + ClickHouse")
        
        while True:
            try:
                mode_choice = input("\nüéØ –í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º (1-3): ").strip()
                if mode_choice in ['1', '2', '3']:
                    break
                print("‚ùå –í–≤–µ–¥–∏—Ç–µ 1, 2 –∏–ª–∏ 3")
            except KeyboardInterrupt:
                print("\nüëã –û–ø–µ—Ä–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
                return
        
        mode_choice = int(mode_choice)
        
        # –í—ã–±–æ—Ä —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ –æ–±–æ—Ä–æ—Ç–Ω—ã–º –∞–≥—Ä–µ–≥–∞—Ç–∞–º (–¥–ª—è –≤—Å–µ—Ö —Ä–µ–∂–∏–º–æ–≤)
        print("\nüìã –§–ò–õ–¨–¢–†–ê–¶–ò–Ø –î–ê–ù–ù–´–•:")
        print("1Ô∏è‚É£  –í–°–ï –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–∞")
        print("2Ô∏è‚É£  –¢–æ–ª—å–∫–æ –û–ë–û–†–û–¢–ù–´–ï –∞–≥—Ä–µ–≥–∞—Ç—ã (37 –ø–∞—Ä—Ç–Ω–æ–º–µ—Ä–æ–≤)")
        
        while True:
            try:
                filter_choice = input("\nüìã –í—ã–±–µ—Ä–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (1-2): ").strip()
                if filter_choice in ['1', '2']:
                    break
                print("‚ùå –í–≤–µ–¥–∏—Ç–µ 1 –∏–ª–∏ 2")
            except KeyboardInterrupt:
                print("\nüëã –û–ø–µ—Ä–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
                return
        
        enable_partno_filter = (filter_choice == '2')
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤–µ—Ä—Å–∏–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Excel
        version_date = extract_version_date_from_excel(file_path, logger)
        if not version_date:
            logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –≤–µ—Ä—Å–∏—é —Ñ–∞–π–ª–∞")
            return
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Excel
        df = load_excel_data(file_path, logger)
        if df is None or df.empty:
            logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ Excel")
            return
        
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –æ–±–æ—Ä–æ—Ç–Ω—ã–º –∞–≥—Ä–µ–≥–∞—Ç–∞–º
        df = filter_by_repairable_partnos(df, logger, enable_partno_filter)
        
        # === –†–ï–ñ–ò–ú 2: –¢–û–õ–¨–ö–û DATAFRAME –° –¶–ò–§–†–û–í–ò–ó–ê–¶–ò–ï–ô ===
        if mode_choice == 2:
            logger.info("üîÑ === –†–ï–ñ–ò–ú: DATAFRAME –° –¶–ò–§–†–û–í–ò–ó–ê–¶–ò–ï–ô ===")
            
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å —Ü–∏—Ñ—Ä–æ–≤–∏–∑–∞—Ü–∏–µ–π
            processed_df = prepare_data_for_clickhouse(df, version_date, logger, enable_partno_filter)
            
            # –¶–∏—Ñ—Ä–æ–≤–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –ø–æ–ª–µ–π
            digital_df = digitize_text_fields(processed_df, logger)
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –≤ —Ñ–∞–π–ª
            output_path = f"test_output/digitized_dataframe_{version_date.strftime('%Y%m%d')}.parquet"
            digital_df.to_parquet(output_path, index=False)
            logger.info(f"üíæ –¶–∏—Ñ—Ä–æ–≤–∏–∑–æ–≤–∞–Ω–Ω—ã–π DataFrame —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_path}")
            
            # –ü–æ–∫–∞–∑ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            display_dataframe_stats(digital_df, logger)
            return
        
        # === –†–ï–ñ–ò–ú 1 –ò 3: –ü–û–î–ö–õ–Æ–ß–ï–ù–ò–ï –ö CLICKHOUSE ===
        if mode_choice in [1, 3]:
            client = connect_clickhouse(config['database']['clickhouse'], logger)
            
            table_name = "heli_raw"
            
            # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
            if not create_table_if_not_exists(client, table_name, logger):
                return
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–∑–º–µ–Ω–µ–Ω–∏–π –¥–∞–Ω–Ω—ã—Ö
            if not check_data_changes(client, table_name, df, version_date, logger):
                logger.info("‚úÖ –ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ - –¥–∞–Ω–Ω—ã–µ –Ω–µ –∏–∑–º–µ–Ω–∏–ª–∏—Å—å")
                return
            
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è ClickHouse
            processed_df = prepare_data_for_clickhouse(df, version_date, logger, enable_partno_filter)
            
            # === –†–ï–ñ–ò–ú 3: –°–û–•–†–ê–ù–ï–ù–ò–ï DATAFRAME –° –¶–ò–§–†–û–í–ò–ó–ê–¶–ò–ï–ô ===
            if mode_choice == 3:
                digital_df = digitize_text_fields(processed_df.copy(), logger)
                output_path = f"test_output/digitized_dataframe_{version_date.strftime('%Y%m%d')}.parquet"
                digital_df.to_parquet(output_path, index=False)
                logger.info(f"üíæ –¶–∏—Ñ—Ä–æ–≤–∏–∑–æ–≤–∞–Ω–Ω—ã–π DataFrame —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_path}")
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö
            if not validate_data_quality(processed_df, logger):
                logger.error("‚ùå –î–∞–Ω–Ω—ã–µ –Ω–µ –ø—Ä–æ—à–ª–∏ –≤–∞–ª–∏–¥–∞—Ü–∏—é –∫–∞—á–µ—Å—Ç–≤–∞")
                return
            
            # –ó–∞–≥—Ä—É–∑–∫–∞ –≤ ClickHouse
            batch_insert_to_clickhouse(client, table_name, processed_df, logger)
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –≤ ClickHouse
            validate_data_in_clickhouse(client, table_name, version_date, logger)
        
        logger.info("üéâ === –ó–ê–ì–†–£–ó–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê –£–°–ü–ï–®–ù–û ===")
        
    except KeyboardInterrupt:
        logger.info("‚ö†Ô∏è –û–ø–µ—Ä–∞—Ü–∏—è –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        logger.error(f"üí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        logger.error(f"üìã –î–µ—Ç–∞–ª–∏: {traceback.format_exc()}")

def digitize_text_fields(df: pd.DataFrame, logger) -> pd.DataFrame:
    """
    –¶–∏—Ñ—Ä–æ–≤–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –ø–æ–ª–µ–π –≤ DataFrame
    –°–æ–∑–¥–∞–Ω–∏–µ ID-–º–∞–ø–ø–∏–Ω–≥–æ–≤ –∏ –±–∏—Ç–æ–≤—ã—Ö –º–∞—Å–æ–∫
    """
    logger.info("üîÑ === –¶–ò–§–†–û–í–ò–ó–ê–¶–ò–Ø –¢–ï–ö–°–¢–û–í–´–• –ü–û–õ–ï–ô ===")
    
    digital_df = df.copy()
    
    # === 1. –°–û–ó–î–ê–ù–ò–ï ID –î–õ–Ø –ü–ê–†–¢–ù–û–ú–ï–†–û–í ===
    unique_partnos = df['partno'].dropna().unique()
    partno_mapping = {partno: idx + 1 for idx, partno in enumerate(sorted(unique_partnos))}
    
    digital_df['partno_id'] = df['partno'].map(partno_mapping)
    logger.info(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(partno_mapping)} ID –¥–ª—è –ø–∞—Ä—Ç–Ω–æ–º–µ—Ä–æ–≤")
    
    # === 2. –°–û–ó–î–ê–ù–ò–ï ID –î–õ–Ø –°–ï–†–ò–ô–ù–´–• –ù–û–ú–ï–†–û–í ===
    unique_serialnos = df['serialno'].dropna().unique()
    serialno_mapping = {serialno: idx + 1 for idx, serialno in enumerate(sorted(unique_serialnos))}
    
    digital_df['serialno_id'] = df['serialno'].map(serialno_mapping)
    logger.info(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(serialno_mapping)} ID –¥–ª—è —Å–µ—Ä–∏–π–Ω—ã—Ö –Ω–æ–º–µ—Ä–æ–≤")
    
    # === 3. –°–û–ó–î–ê–ù–ò–ï ID –î–õ–Ø –õ–û–ö–ê–¶–ò–ô ===
    unique_locations = df['location'].dropna().unique()
    location_mapping = {location: idx + 1 for idx, location in enumerate(sorted(unique_locations))}
    
    digital_df['location_id'] = df['location'].map(location_mapping)
    logger.info(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(location_mapping)} ID –¥–ª—è –ª–æ–∫–∞—Ü–∏–π")
    
    # === 4. –ë–ò–¢–û–í–´–ï –ú–ê–°–ö–ò –î–õ–Ø –¢–ò–ü–û–í –í–° ===
    ac_type_masks = {
        '–ú–∏-26': 128, '–ú–ò26–¢': 128,    # 0b10000000
        '–ú–∏-17': 64,                    # 0b01000000  
        '–ú–∏-8–¢': 32,                    # 0b00100000
        '–ö–∞-32': 16,                    # 0b00010000
        'AS-350': 8, '350B3': 8,        # 0b00001000
        'AS-355': 4, '355NP': 4,        # 0b00000100
        'R-44': 2,                      # 0b00000010
    }
    
    digital_df['ac_typ_mask'] = df['ac_typ'].map(ac_type_masks).fillna(0).astype('uint8')
    logger.info(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(ac_type_masks)} –±–∏—Ç–æ–≤—ã—Ö –º–∞—Å–æ–∫ –¥–ª—è —Ç–∏–ø–æ–≤ –í–°")
    
    # === 5. –ë–ò–¢–û–í–´–ï –ú–ê–°–ö–ò –î–õ–Ø –°–û–°–¢–û–Ø–ù–ò–ô ===
    condition_mapping = {
        '–ò–°–ü–†–ê–í–ù–´–ô': 7,        # 0b111 - –≠–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏—è
        '–ù–ï–ò–°–ü–†–ê–í–ù–´–ô': 4,      # 0b100 - –†–µ–º–æ–Ω—Ç  
        '–î–û–ù–û–†': 1,            # 0b001 - –•—Ä–∞–Ω–µ–Ω–∏–µ
        '–°–ù–Ø–¢ –ó–ê–ö–ê–ó–ß–ò–ö–û–ú': 0,  # 0b000 - –ù–µ–∞–∫—Ç–∏–≤–Ω–æ
        '–°–ù–Ø–¢': 0,             # 0b000 - –ù–µ–∞–∫—Ç–∏–≤–Ω–æ
        '–ù–ï –£–°–¢–ê–ù–û–í–õ–ï–ù': 6,    # 0b110 - –ò—Å–ø—Ä–∞–≤–µ–Ω, —Å—á–µ—Ç—á–∏–∫–∏ –Ω–µ —Ä–∞–±–æ—Ç–∞—é—Ç
        '–ü–û–°–¢–ê–í–ö–ê': 3,         # 0b011 - –†–µ–∑–µ—Ä–≤
    }
    
    digital_df['condition_mask'] = df['condition'].map(condition_mapping).fillna(0).astype('uint8')
    logger.info(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(condition_mapping)} –±–∏—Ç–æ–≤—ã—Ö –º–∞—Å–æ–∫ –¥–ª—è —Å–æ—Å—Ç–æ—è–Ω–∏–π")
    
    # === 6. ID –î–õ–Ø –í–õ–ê–î–ï–õ–¨–¶–ï–í ===
    owner_mapping = {
        '–Æ–¢-–í–£': 1, 'UTE': 2, '–ì–¢–õ–ö': 3, '–°–ë–ï–† –õ–ò–ó–ò–ù–ì': 4,
        '–ì–ü–ú': 5, '–ê–û –ì–ü–ú': 6, '–ò–ü': 7, '–ê–†–í': 8, '–ò': 9
    }
    
    digital_df['owner_id'] = df['owner'].map(owner_mapping).fillna(0).astype('uint8')
    logger.info(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(owner_mapping)} ID –¥–ª—è –≤–ª–∞–¥–µ–ª—å—Ü–µ–≤")
    
    # === 7. –°–û–•–†–ê–ù–ï–ù–ò–ï –ú–ê–ü–ü–ò–ù–ì–û–í ===
    mappings = {
        'partno_mapping': partno_mapping,
        'serialno_mapping': serialno_mapping,
        'location_mapping': location_mapping,
        'ac_type_masks': ac_type_masks,
        'condition_mapping': condition_mapping,
        'owner_mapping': owner_mapping
    }
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–∞–ø–ø–∏–Ω–≥–æ–≤ –≤ JSON –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    import json
    mapping_file = f"test_output/field_mappings_{pd.Timestamp.now().strftime('%Y%m%d')}.json"
    with open(mapping_file, 'w', encoding='utf-8') as f:
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤—Å–µ –≤ —Å—Ç—Ä–æ–∫–∏ –¥–ª—è JSON —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏
        json_mappings = {}
        for key, mapping in mappings.items():
            json_mappings[key] = {str(k): int(v) for k, v in mapping.items()}
        json.dump(json_mappings, f, ensure_ascii=False, indent=2)
    
    logger.info(f"üíæ –ú–∞–ø–ø–∏–Ω–≥–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {mapping_file}")
    
    return digital_df

def display_dataframe_stats(df: pd.DataFrame, logger):
    """–û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ü–∏—Ñ—Ä–æ–≤–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ DataFrame"""
    logger.info("üìä === –°–¢–ê–¢–ò–°–¢–ò–ö–ê –¶–ò–§–†–û–í–ò–ó–û–í–ê–ù–ù–û–ì–û DATAFRAME ===")
    
    # –û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
    logger.info(f"üìÑ –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {len(df):,}")
    logger.info(f"üìã –í—Å–µ–≥–æ –∫–æ–ª–æ–Ω–æ–∫: {len(df.columns)}")
    
    # –ò—Å—Ö–æ–¥–Ω—ã–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –ø–æ–ª—è
    text_fields = ['partno', 'serialno', 'location', 'ac_typ', 'condition', 'owner']
    digital_fields = ['partno_id', 'serialno_id', 'location_id', 'ac_typ_mask', 'condition_mask', 'owner_id']
    
    logger.info("\nüîÑ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∏—Å—Ö–æ–¥–Ω—ã—Ö –∏ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö –ø–æ–ª–µ–π:")
    for text_field, digital_field in zip(text_fields, digital_fields):
        if text_field in df.columns and digital_field in df.columns:
            unique_text = df[text_field].nunique()
            unique_digital = df[digital_field].nunique()
            logger.info(f"  {text_field:15} ‚Üí {digital_field:15}: {unique_text:4} ‚Üí {unique_digital:4} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö")
    
    # –ë–∏—Ç–æ–≤—ã–µ –º–∞—Å–∫–∏
    if 'ac_typ_mask' in df.columns:
        mask_stats = df['ac_typ_mask'].value_counts().sort_index()
        logger.info(f"\nüé≠ –ë–∏—Ç–æ–≤—ã–µ –º–∞—Å–∫–∏ —Ç–∏–ø–æ–≤ –í–°:")
        for mask, count in mask_stats.items():
            if mask > 0:
                logger.info(f"  –ú–∞—Å–∫–∞ {mask:3} (0b{mask:08b}): {count:,} –∑–∞–ø–∏—Å–µ–π")
    
    # –†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö
    memory_usage = df.memory_usage(deep=True).sum() / 1024 / 1024
    logger.info(f"\nüíæ –†–∞–∑–º–µ—Ä DataFrame –≤ –ø–∞–º—è—Ç–∏: {memory_usage:.2f} MB")
    
    # –ü–æ–∫–∞–∑–∞—Ç—å –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –∑–∞–ø–∏—Å–µ–π
    logger.info(f"\nüìã –ü–µ—Ä–≤—ã–µ 3 –∑–∞–ø–∏—Å–∏ —Ü–∏—Ñ—Ä–æ–≤–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:")
    display_cols = [col for col in ['partno_id', 'serialno_id', 'ac_typ_mask', 'condition_mask'] if col in df.columns]
    if display_cols:
        sample_data = df[display_cols].head(3)
        for idx, row in sample_data.iterrows():
            logger.info(f"  –ó–∞–ø–∏—Å—å {idx}: {dict(row)}")

def validate_data_in_clickhouse(client, table_name, version_date, logger):
    """
    –ü–æ—Å—Ç–∑–∞–≥—Ä—É–∑–æ—á–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –≤ ClickHouse
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å –∏ –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏
    """
    logger.info("üîç –ü—Ä–æ–≤–µ–¥–µ–Ω–∏–µ –ø–æ—Å—Ç–∑–∞–≥—Ä—É–∑–æ—á–Ω–æ–π –≤–∞–ª–∏–¥–∞—Ü–∏–∏...")
    
    validation_queries = [
        ("–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π", f"SELECT count(*) FROM {table_name} WHERE version_date = '{version_date}'"),
        ("–ü—É—Å—Ç—ã–µ –ø–∞—Ä—Ç–Ω–æ–º–µ—Ä–∞", f"SELECT count(*) FROM {table_name} WHERE version_date = '{version_date}' AND (partno = '' OR partno IS NULL)"),
        ("–ü—É—Å—Ç—ã–µ —Å–µ—Ä–∏–π–Ω—ã–µ –Ω–æ–º–µ—Ä–∞", f"SELECT count(*) FROM {table_name} WHERE version_date = '{version_date}' AND (serialno = '' OR serialno IS NULL)"),
        ("–î—É–±–ª–∏–∫–∞—Ç—ã –ø–æ –∫–ª—é—á—É", f"SELECT partno, serialno, count(*) as cnt FROM {table_name} WHERE version_date = '{version_date}' GROUP BY partno, serialno HAVING cnt > 1 LIMIT 5"),
        ("–û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ SNE", f"SELECT count(*) FROM {table_name} WHERE version_date = '{version_date}' AND sne < 0"),
        ("–û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ PPR", f"SELECT count(*) FROM {table_name} WHERE version_date = '{version_date}' AND ppr < 0"),
        ("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ SNE", f"SELECT min(sne), max(sne), avg(sne), median(sne) FROM {table_name} WHERE version_date = '{version_date}' AND sne > 0"),
        ("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ PPR", f"SELECT min(ppr), max(ppr), avg(ppr), median(ppr) FROM {table_name} WHERE version_date = '{version_date}' AND ppr > 0"),
        ("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏–π", f"SELECT condition, count(*) FROM {table_name} WHERE version_date = '{version_date}' GROUP BY condition ORDER BY count(*) DESC"),
        ("–£–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Ç–∏–ø—ã –í–°", f"SELECT ac_typ, count(*) FROM {table_name} WHERE version_date = '{version_date}' GROUP BY ac_typ ORDER BY count(*) DESC"),
    ]
    
    validation_passed = True
    
    for description, query in validation_queries:
        try:
            logger.info(f"üîç {description}...")
            result = client.execute(query)
            
            if "count(*)" in query and len(result) == 1:
                count = result[0][0]
                logger.info(f"   üìä {description}: {count:,}")
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π
                if "–ü—É—Å—Ç—ã–µ –ø–∞—Ä—Ç–Ω–æ–º–µ—Ä–∞" in description and count > 0:
                    logger.error(f"   ‚ùå –ù–∞–π–¥–µ–Ω–æ {count} –∑–∞–ø–∏—Å–µ–π —Å –ø—É—Å—Ç—ã–º–∏ –ø–∞—Ä—Ç–Ω–æ–º–µ—Ä–∞–º–∏!")
                    validation_passed = False
                elif "–î—É–±–ª–∏–∫–∞—Ç—ã –ø–æ –∫–ª—é—á—É" in description and len(result) > 0:
                    logger.error(f"   ‚ùå –ù–∞–π–¥–µ–Ω—ã –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ –∫–ª—é—á—É!")
                    for row in result:
                        logger.error(f"      partno: {row[0]}, serialno: {row[1]}, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ: {row[2]}")
                    validation_passed = False
                elif "–û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ" in description and count > 0:
                    logger.warning(f"   ‚ö†Ô∏è  –ù–∞–π–¥–µ–Ω–æ {count} –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π")
                    
            elif "–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏" in description and len(result) == 1:
                stats = result[0]
                field_name = "SNE" if "SNE" in description else "PPR"
                logger.info(f"   üìà {field_name}: –º–∏–Ω={stats[0]:.2f}, –º–∞–∫—Å={stats[1]:.2f}, —Å—Ä–µ–¥–Ω–µ–µ={stats[2]:.2f}, –º–µ–¥–∏–∞–Ω–∞={stats[3]:.2f}")
                
            elif "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ" in description or "–£–Ω–∏–∫–∞–ª—å–Ω—ã–µ" in description:
                logger.info(f"   üìä –ù–∞–π–¥–µ–Ω–æ {len(result)} —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π:")
                for i, row in enumerate(result[:5]):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 5
                    logger.info(f"      {row[0]}: {row[1]:,} –∑–∞–ø–∏—Å–µ–π")
                if len(result) > 5:
                    logger.info(f"      ... –∏ –µ—â–µ {len(result) - 5} –∑–Ω–∞—á–µ–Ω–∏–π")
                    
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ '{description}': {e}")
            validation_passed = False
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏
    try:
        logger.info("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö...")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–µ—Ä—Å–∏–π –¥–∞–Ω–Ω—ã—Ö
        versions_query = f"SELECT DISTINCT version_date, count(*) FROM {table_name} GROUP BY version_date ORDER BY version_date DESC LIMIT 5"
        versions_result = client.execute(versions_query)
        
        logger.info("üìÖ –ü–æ—Å–ª–µ–¥–Ω–∏–µ –≤–µ—Ä—Å–∏–∏ –¥–∞–Ω–Ω—ã—Ö:")
        for version, count in versions_result:
            status = "üü¢ –¢–ï–ö–£–©–ê–Ø" if version.strftime('%Y-%m-%d') == version_date else "üîµ"
            logger.info(f"   {status} {version.strftime('%Y-%m-%d')}: {count:,} –∑–∞–ø–∏—Å–µ–π")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏ –¥–∞—Ç
        date_check_query = f"""
        SELECT count(*) 
        FROM {table_name} 
        WHERE version_date = '{version_date}' 
          AND mfg_date > removal_date 
          AND removal_date IS NOT NULL 
          AND mfg_date IS NOT NULL
        """
        date_issues = client.execute(date_check_query)[0][0]
        
        if date_issues > 0:
            logger.error(f"‚ùå –ù–∞–π–¥–µ–Ω–æ {date_issues} –∑–∞–ø–∏—Å–µ–π —Å –¥–∞—Ç–æ–π —Å–Ω—è—Ç–∏—è —Ä–∞–Ω—å—à–µ –¥–∞—Ç—ã –∏–∑–≥–æ—Ç–æ–≤–ª–µ–Ω–∏—è!")
            validation_passed = False
        else:
            logger.info("‚úÖ –î–∞—Ç—ã –∏–∑–≥–æ—Ç–æ–≤–ª–µ–Ω–∏—è –∏ —Å–Ω—è—Ç–∏—è –ª–æ–≥–∏—á–µ—Å–∫–∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã")
            
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏: {e}")
        validation_passed = False
    
    # –ò—Ç–æ–≥–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞
    if validation_passed:
        logger.info("üéâ === –ü–û–°–¢–ó–ê–ì–†–£–ó–û–ß–ù–ê–Ø –í–ê–õ–ò–î–ê–¶–ò–Ø –£–°–ü–ï–®–ù–ê ===")
        logger.info("‚úÖ –í—Å–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–æ–π–¥–µ–Ω—ã")
    else:
        logger.error("üí• === –û–ë–ù–ê–†–£–ñ–ï–ù–´ –ü–†–û–ë–õ–ï–ú–´ –ü–û–°–õ–ï –ó–ê–ì–†–£–ó–ö–ò ===")
        logger.error("‚ùå –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –Ω–µ –ø—Ä–æ–π–¥–µ–Ω—ã")
        logger.error("üîß –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –∏ –∏—Å–ø—Ä–∞–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ")
    
    return validation_passed

if __name__ == '__main__':
    main() 